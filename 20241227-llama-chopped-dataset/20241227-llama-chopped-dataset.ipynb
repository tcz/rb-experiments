{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 fine tuning with \"chopped\" dataset\n",
    "\n",
    "2024-12-27 12:47\n",
    "\n",
    "Over a week of fine-tuning on the chopped data set. Unfortunately the training froze several times without an error message and had to be restarted. It's probably the metrics calculation. The loss did not improve over time and the output is garbage, although I suspect this might have something to do with the checkpoints not being properly \"picked back up\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8567da-339d-42d8-a672-fd9474f75a04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /opt/conda/lib/python3.11/site-packages (2024.12.4)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mFound existing installation: unsloth 2024.12.4\n",
      "Uninstalling unsloth-2024.12.4:\n",
      "  Successfully uninstalled unsloth-2024.12.4\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-h4lvy1ls/unsloth_effc2adce2d74bbc8cd0e9c5ae3463cb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-h4lvy1ls/unsloth_effc2adce2d74bbc8cd0e9c5ae3463cb\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 85f1fa096afde5efe2fb8521d8ceec8d13a00715\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: unsloth_zoo>=2024.11.8 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
      "Requirement already satisfied: tyro in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.2)\n",
      "Requirement already satisfied: transformers>=4.46.1 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.46.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.5)\n",
      "Requirement already satisfied: hf_transfer in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: bitsandbytes>=0.43.3 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.12.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.12.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.4.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.15.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.3)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for unsloth: filename=unsloth-2024.12.4-py3-none-any.whl size=173746 sha256=9c89f156945dea9b5d2b992c9f133771578b56b14f52d5cdec71cf902d29ce2c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hl73b2e/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.12.4\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.11/site-packages (2.4.3)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (3.0.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2.2.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (5.3.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: pytest-playwright in /opt/conda/lib/python3.11/site-packages (0.6.2)\n",
      "Requirement already satisfied: playwright>=1.18 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (1.49.1)\n",
      "Requirement already satisfied: pytest<9.0.0,>=6.2.4 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.3.3)\n",
      "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (2.1.0)\n",
      "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.0.4)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (3.1.1)\n",
      "Requirement already satisfied: pyee==12.0.0 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from pyee==12.0.0->playwright>=1.18->pytest-playwright) (4.11.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.9 in /opt/conda/lib/python3.11/site-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.32.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.11/site-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2024.7.4)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (10.4.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: lpips in /opt/conda/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (1.14.1)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.2.1->lpips) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=0.4.0->lpips) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mInstalling dependencies...\n",
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease \n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Fetched 384 kB in 1s (314 kB/s)  \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
      "fonts-liberation is already the newest version (1:1.07.4-11).\n",
      "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
      "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
      "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
      "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
      "libcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libdbus-glib-1-2 is already the newest version (0.112-2build1).\n",
      "libegl1 is already the newest version (1.4.0-1).\n",
      "libenchant-2-2 is already the newest version (2.3.2-1ubuntu2).\n",
      "libepoxy0 is already the newest version (1.5.10-1).\n",
      "libevdev2 is already the newest version (1.12.1+dfsg-1).\n",
      "libevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\n",
      "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
      "libgles2 is already the newest version (1.4.0-1).\n",
      "libglx0 is already the newest version (1.4.0-1).\n",
      "libgudev-1.0-0 is already the newest version (1:237-2build1).\n",
      "libhyphen0 is already the newest version (2.8.8-7build2).\n",
      "libicu70 is already the newest version (70.1-2).\n",
      "libjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\n",
      "liblcms2-2 is already the newest version (2.12~rc1-2build2).\n",
      "libmanette-0.2-0 is already the newest version (0.2.6-3build1).\n",
      "libopengl0 is already the newest version (1.4.0-1).\n",
      "libopus0 is already the newest version (1.3.1-0.1build2).\n",
      "libpng16-16 is already the newest version (1.6.37-3build5).\n",
      "libproxy1v5 is already the newest version (0.4.17-2).\n",
      "libsecret-1-0 is already the newest version (0.20.5-2).\n",
      "libwoff1 is already the newest version (1.0.2-1build4).\n",
      "libxcb-shm0 is already the newest version (1.14-3ubuntu3).\n",
      "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
      "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
      "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
      "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
      "libxext6 is already the newest version (2:1.3.4-1build1).\n",
      "libxfixes3 is already the newest version (1:6.0.0-1).\n",
      "libxi6 is already the newest version (2:1.8-1build1).\n",
      "libxkbcommon0 is already the newest version (1.4.0-1).\n",
      "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
      "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
      "libxtst6 is already the newest version (2:1.2.3-1build4).\n",
      "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
      "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
      "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
      "fonts-unifont is already the newest version (1:14.0.01-1).\n",
      "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
      "libavif13 is already the newest version (0.9.3-3).\n",
      "libffi7 is already the newest version (3.3-5ubuntu1).\n",
      "libx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\n",
      "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
      "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-plugins-base is already the newest version (1.20.1-1ubuntu0.2).\n",
      "gstreamer1.0-plugins-good is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libatomic1 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
      "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
      "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
      "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
      "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
      "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
      "libgdk-pixbuf-2.0-0 is already the newest version (2.42.8+dfsg-1ubuntu0.3).\n",
      "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
      "libgstreamer-gl1.0-0 is already the newest version (1.20.1-1ubuntu0.2).\n",
      "libgstreamer-plugins-base1.0-0 is already the newest version (1.20.1-1ubuntu0.2).\n",
      "libgstreamer1.0-0 is already the newest version (1.20.3-0ubuntu1).\n",
      "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\n",
      "libharfbuzz-icu0 is already the newest version (2.7.4-1ubuntu3.1).\n",
      "libharfbuzz0b is already the newest version (2.7.4-1ubuntu3.1).\n",
      "libnotify4 is already the newest version (0.7.9-3ubuntu5.22.04.1).\n",
      "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
      "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
      "libopenjp2-7 is already the newest version (2.4.0-6ubuntu0.2).\n",
      "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\n",
      "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libxml2 is already the newest version (2.9.13+dfsg-1ubuntu0.4).\n",
      "libxslt1.1 is already the newest version (1.1.34-4ubuntu0.22.04.1).\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-libav is already the newest version (1.20.3-0ubuntu1).\n",
      "gstreamer1.0-plugins-bad is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libsoup-3.0-0 is already the newest version (3.0.7-0ubuntu1).\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.2.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (69.5.1)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "!pip install sacrebleu\n",
    "!pip install pytest-playwright\n",
    "!playwright install\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install torchvision\n",
    "!pip install lpips\n",
    "\n",
    "!playwright install-deps  \n",
    "\n",
    "!pip install -U numpy\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 131_072\n",
    "\n",
    "def load_model():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=\"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    \n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "        use_rslora=True,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state = 32,\n",
    "        loftq_config = None,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167425bb45a12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, training_data, max_steps):\n",
    "    training_arguments = TrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=64,\n",
    "        num_train_epochs=1,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        # max_steps=max_steps,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=10,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    if max_steps is not None:\n",
    "        training_arguments.max_steps = max_steps\n",
    "\n",
    "    print(training_data)\n",
    "    \n",
    "    return SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=training_data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=10,\n",
    "        packing=True,\n",
    "        args=training_arguments,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label)\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    results = {\n",
    "        \"similarity\": float(np.mean(similarity_scores)),\n",
    "        \"perceptual_loss\": float(np.mean(perceptual_losses)),\n",
    "    }\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', results['similarity'], steps)\n",
    "    writer.add_scalar('perceptual_loss', results['perceptual_loss'], steps)\n",
    "    \n",
    "    print(\"Similarity:\", results['similarity'])\n",
    "    print(\"Perceptual loss:\", results['perceptual_loss'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9436b4-22de-4180-a7d6-9aad00934c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c8b3c6163163d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-12build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
      "--2024-12-15 14:04:33--  https://www.dropbox.com/scl/fi/hsqsp79okuob4u63oj7j3/data-rb-chopped.zip?rlkey=ey3a4ap5h6v9mcaava1bps52n&dl=11\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.13.18, 2620:100:6057:18::a27d:d12\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.13.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com/cd/0/inline/CgSsviUjyh4F-Ioi5qCgpIEVkA_HQeyK3USE0VNoq0wVHxIBaHYcDQUfWrZQneIvq4NosSBlMK1nFDlxyoGWFYRrc9BxSAV8H47FkmLWdQwzgIzHx8-1iXw86XXCi-tPJec/file# [following]\n",
      "--2024-12-15 14:04:34--  https://uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com/cd/0/inline/CgSsviUjyh4F-Ioi5qCgpIEVkA_HQeyK3USE0VNoq0wVHxIBaHYcDQUfWrZQneIvq4NosSBlMK1nFDlxyoGWFYRrc9BxSAV8H47FkmLWdQwzgIzHx8-1iXw86XXCi-tPJec/file\n",
      "Resolving uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com (uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6057:15::a27d:d0f\n",
      "Connecting to uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com (uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com)|162.125.13.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CgQI7FbHs7lprAuXSlFqHp_Z5jbiNAfHzskcd_17RFx6gJ39ZdkjiVfXpTRZdKP4PsDWPXssus2X8D0q3fWDkQEqUBtmk4THcmJ8CU75jKamn7MW7EGNypthTs2E54nCOzY8CMcpk9IHO9fjsDlb4mEDeHia1gqnM3gK7lJ5CoJuY7sU9fFdz1cKGwFClacUJwjApshiYOBVtTpWgVi1gvaY9msIY9OPO9IP8mAVr15Eoty9XBd1DSS1iw0auO9Yy_eBYDkSRcFB6w7hOEmsL50dE-9vxqyY5edkxy2gvY55fRBcTjSQT09y2mSnLKh2A8s3jLJEYDiw_ZFaxkwhoXfDNMO0HxRyEZXcAyQIWTr8Bw/file [following]\n",
      "--2024-12-15 14:04:35--  https://uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com/cd/0/inline2/CgQI7FbHs7lprAuXSlFqHp_Z5jbiNAfHzskcd_17RFx6gJ39ZdkjiVfXpTRZdKP4PsDWPXssus2X8D0q3fWDkQEqUBtmk4THcmJ8CU75jKamn7MW7EGNypthTs2E54nCOzY8CMcpk9IHO9fjsDlb4mEDeHia1gqnM3gK7lJ5CoJuY7sU9fFdz1cKGwFClacUJwjApshiYOBVtTpWgVi1gvaY9msIY9OPO9IP8mAVr15Eoty9XBd1DSS1iw0auO9Yy_eBYDkSRcFB6w7hOEmsL50dE-9vxqyY5edkxy2gvY55fRBcTjSQT09y2mSnLKh2A8s3jLJEYDiw_ZFaxkwhoXfDNMO0HxRyEZXcAyQIWTr8Bw/file\n",
      "Reusing existing connection to uc3f648558af4ef362476eb55a1d.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1289698689 (1.2G) [application/zip]\n",
      "Saving to: â€˜model.zipâ€™\n",
      "\n",
      "model.zip           100%[===================>]   1.20G  19.7MB/s    in 65s     \n",
      "\n",
      "2024-12-15 14:05:41 (19.0 MB/s) - â€˜model.zipâ€™ saved [1289698689/1289698689]\n",
      "\n",
      "Archive:  model.zip\n",
      "  inflating: data-rb-chopped/dataset_info.json  \n",
      "  inflating: data-rb-chopped/__MACOSX/._dataset_info.json  \n",
      "  inflating: data-rb-chopped/state.json  \n",
      "  inflating: data-rb-chopped/__MACOSX/._state.json  \n",
      "  inflating: data-rb-chopped/data-00014-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00014-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00013-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00013-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00012-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00012-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00011-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00011-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00010-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00010-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00009-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00009-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00008-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00008-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00007-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00007-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00006-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00006-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00005-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00005-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00004-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00004-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00003-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00003-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00002-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00002-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00001-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00001-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/data-00000-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/__MACOSX/._data-00000-of-00015.arrow  \n",
      "  inflating: data-rb-chopped/tokenizer.json  \n",
      "  inflating: data-rb-chopped/__MACOSX/._tokenizer.json  \n",
      "--2024-12-15 14:06:21--  https://www.dropbox.com/scl/fi/5szml8y5l248mcabj9rqg/verify-dataset.zip?rlkey=se33rwtxgngn0ts1i0pc8f6wk&st=1d68x9zt&dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.13.18, 2620:100:6057:18::a27d:d12\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.13.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com/cd/0/inline/CgTBtId7ysaBRDSKDcVQhELIVIlYHgVhl6GtUbO_6-C6sDeKKONFLpg5cXKQ2R7ojsyAOI-QO5tUm9i9zmV1RtbuMPxpFdM6o-NYPbUossEl6tB8389Ng1LKEqYMIbdnD0U/file?dl=1# [following]\n",
      "--2024-12-15 14:06:22--  https://uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com/cd/0/inline/CgTBtId7ysaBRDSKDcVQhELIVIlYHgVhl6GtUbO_6-C6sDeKKONFLpg5cXKQ2R7ojsyAOI-QO5tUm9i9zmV1RtbuMPxpFdM6o-NYPbUossEl6tB8389Ng1LKEqYMIbdnD0U/file?dl=1\n",
      "Resolving uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com (uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6057:15::a27d:d0f\n",
      "Connecting to uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com (uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com)|162.125.13.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CgQIttG8pV7dGfQqazO38ersXnwxY--CpZq5Qm5GJesAAIxAwJY1hr0B4_Ayok-7XXW5C0EuKklJhCF7VWoBW59Tk41IRGuSm3wbYbCHZakXDVUFD_msyUGXTmoLgJiyaYU3az4h4tmUoqLjtuZQjUf3MZJf7foloE3sS2JtjAjbc-wGDn65E0Ga_lECOZzteYcYFolMh5NFvCnQOTIeD61VmssFHE5-p4SDRQ4T3lJWI33U7TE3HCUCYKqBbgqb1Xe4MhuJgNRWW3I7x1X1H44xBQznJ0VS6o7rjCaPcWCjZIa1BiKuAH6lEtnGbSRWwwUmmfIjNy5otePystGS-eZUc41XoWxlg2eRqLMsehz_tg/file?dl=1 [following]\n",
      "--2024-12-15 14:06:23--  https://uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com/cd/0/inline2/CgQIttG8pV7dGfQqazO38ersXnwxY--CpZq5Qm5GJesAAIxAwJY1hr0B4_Ayok-7XXW5C0EuKklJhCF7VWoBW59Tk41IRGuSm3wbYbCHZakXDVUFD_msyUGXTmoLgJiyaYU3az4h4tmUoqLjtuZQjUf3MZJf7foloE3sS2JtjAjbc-wGDn65E0Ga_lECOZzteYcYFolMh5NFvCnQOTIeD61VmssFHE5-p4SDRQ4T3lJWI33U7TE3HCUCYKqBbgqb1Xe4MhuJgNRWW3I7x1X1H44xBQznJ0VS6o7rjCaPcWCjZIa1BiKuAH6lEtnGbSRWwwUmmfIjNy5otePystGS-eZUc41XoWxlg2eRqLMsehz_tg/file?dl=1\n",
      "Reusing existing connection to uc5a0ccfa1dec44ccb5428090f6d.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 238890 (233K) [application/binary]\n",
      "Saving to: â€˜validate.zipâ€™\n",
      "\n",
      "validate.zip        100%[===================>] 233.29K   443KB/s    in 0.5s    \n",
      "\n",
      "2024-12-15 14:06:24 (443 KB/s) - â€˜validate.zipâ€™ saved [238890/238890]\n",
      "\n",
      "Archive:  validate.zip\n",
      "  inflating: data-rb-validate/1aaaf27b.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._1aaaf27b.webp  \n",
      "  inflating: data-rb-validate/1c52383e.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._1c52383e.webp  \n",
      "  inflating: data-rb-validate/3e290f44.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._3e290f44.webp  \n",
      "  inflating: data-rb-validate/4fb8a91d.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._4fb8a91d.svg  \n",
      "  inflating: data-rb-validate/5bcd31b6.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._5bcd31b6.svg  \n",
      "  inflating: data-rb-validate/6e16da92.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._6e16da92.webp  \n",
      "  inflating: data-rb-validate/8a2b68c6.png  \n",
      "  inflating: data-rb-validate/__MACOSX/._8a2b68c6.png  \n",
      "  inflating: data-rb-validate/9ecf718d.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._9ecf718d.webp  \n",
      "  inflating: data-rb-validate/23d48054.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._23d48054.svg  \n",
      "  inflating: data-rb-validate/98c84b88.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._98c84b88.svg  \n",
      "  inflating: data-rb-validate/856c44ec.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._856c44ec.webp  \n",
      "  inflating: data-rb-validate/984b9c32.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._984b9c32.svg  \n",
      "  inflating: data-rb-validate/601060ec.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._601060ec.webp  \n",
      "  inflating: data-rb-validate/892130e0.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._892130e0.webp  \n",
      "  inflating: data-rb-validate/02836284.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._02836284.webp  \n",
      "  inflating: data-rb-validate/5252267a.png  \n",
      "  inflating: data-rb-validate/__MACOSX/._5252267a.png  \n",
      "  inflating: data-rb-validate/a5b2d81a.png  \n",
      "  inflating: data-rb-validate/__MACOSX/._a5b2d81a.png  \n",
      "  inflating: data-rb-validate/a6ead9ac.png  \n",
      "  inflating: data-rb-validate/__MACOSX/._a6ead9ac.png  \n",
      "  inflating: data-rb-validate/a717d05d.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._a717d05d.webp  \n",
      "  inflating: data-rb-validate/ab9a847d.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._ab9a847d.svg  \n",
      "  inflating: data-rb-validate/ab484cc8.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._ab484cc8.webp  \n",
      "  inflating: data-rb-validate/af2a513d.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._af2a513d.svg  \n",
      "  inflating: data-rb-validate/b1b77f6b.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._b1b77f6b.webp  \n",
      "  inflating: data-rb-validate/b0870752.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._b0870752.svg  \n",
      "  inflating: data-rb-validate/baa1933a.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._baa1933a.svg  \n",
      "  inflating: data-rb-validate/d06fd4eb.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._d06fd4eb.webp  \n",
      "  inflating: data-rb-validate/d7e122fe.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._d7e122fe.svg  \n",
      "  inflating: data-rb-validate/d62090d3.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._d62090d3.webp  \n",
      "  inflating: data-rb-validate/da43c904.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._da43c904.webp  \n",
      "  inflating: data-rb-validate/data-00000-of-00001.arrow  \n",
      "  inflating: data-rb-validate/__MACOSX/._data-00000-of-00001.arrow  \n",
      "  inflating: data-rb-validate/dataset_info.json  \n",
      "  inflating: data-rb-validate/__MACOSX/._dataset_info.json  \n",
      "  inflating: data-rb-validate/dataset.json  \n",
      "  inflating: data-rb-validate/__MACOSX/._dataset.json  \n",
      "  inflating: data-rb-validate/db5da240.jpeg  \n",
      "  inflating: data-rb-validate/__MACOSX/._db5da240.jpeg  \n",
      "  inflating: data-rb-validate/e382e81f.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._e382e81f.svg  \n",
      "  inflating: data-rb-validate/eb6efbc1.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._eb6efbc1.webp  \n",
      "  inflating: data-rb-validate/ed34bf8f.webp  \n",
      "  inflating: data-rb-validate/__MACOSX/._ed34bf8f.webp  \n",
      "  inflating: data-rb-validate/f778a87c.svg  \n",
      "  inflating: data-rb-validate/__MACOSX/._f778a87c.svg  \n",
      "  inflating: data-rb-validate/SDK_CRAWLER_STATISTICS_0.json  \n",
      "  inflating: data-rb-validate/__MACOSX/._SDK_CRAWLER_STATISTICS_0.json  \n",
      "  inflating: data-rb-validate/SDK_SESSION_POOL_STATE.json  \n",
      "  inflating: data-rb-validate/__MACOSX/._SDK_SESSION_POOL_STATE.json  \n",
      "  inflating: data-rb-validate/state.json  \n",
      "  inflating: data-rb-validate/__MACOSX/._state.json  \n"
     ]
    }
   ],
   "source": [
    "!apt install zip -y\n",
    "!rm -rf data-rb-chopped\n",
    "!mkdir -p data-rb-chopped\n",
    "!wget \"https://www.dropbox.com/scl/fi/hsqsp79okuob4u63oj7j3/data-rb-chopped.zip?rlkey=ey3a4ap5h6v9mcaava1bps52n&dl=11\" -O model.zip\n",
    "!unzip model.zip -d data-rb-chopped\n",
    "\n",
    "!rm -rf data-rb-validate\n",
    "!mkdir -p data-rb-validate\n",
    "!wget \"https://www.dropbox.com/scl/fi/5szml8y5l248mcabj9rqg/verify-dataset.zip?rlkey=se33rwtxgngn0ts1i0pc8f6wk&st=1d68x9zt&dl=1\" -O validate.zip\n",
    "!unzip validate.zip -d data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f3d9ae5b9b9f7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html'],\n",
       "        num_rows: 214811\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('data-rb-chopped')\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=1/len(dataset))\n",
    "visual_validation_dataset = load_from_disk('data-rb-validate')\n",
    "\n",
    "dataset['test'] = dataset['test'].add_item(visual_validation_dataset[0])\n",
    "dataset['test'] = dataset['test'].add_item(visual_validation_dataset[1])\n",
    "dataset['test'] = dataset['test'].add_item(visual_validation_dataset[2])\n",
    "dataset['test'] = dataset['test'].add_item(visual_validation_dataset[3])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bf3a2cdcc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.003 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.4 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model()\n",
    "\n",
    "data_prompt = \"\"\"Your job is to take an SVG file of a web design and convert it into a pixel-perfect HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"svg\"]\n",
    "    outputs      = examples[\"html\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f57abcb9-04a6-4ad6-91af-7fd09e7118ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f238e66aaf04c7399ff934f3a316317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a601fe1c06342ce8587b4209835bea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335b25f6-18b9-4ac9-bad7-2d6ccfe2355b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 214811\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8289ee3c-34eb-4ca3-b69b-2e7a2828a418",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11f8fda61cd48fc9525575276ac7313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faef241ccb845b5907a73797529e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc6d71330a24af4b95f143e9d74bcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/214811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641397a9dcc44064834c0c3a257e7aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 125950\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def get_token_lengths(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=False,  # Don't truncate yet\n",
    "        padding=False,     # Don't pad yet\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = training_data.map(get_token_lengths, batched=True)\n",
    "\n",
    "def filter_function(example):\n",
    "    return example['length'] <= max_seq_length\n",
    "\n",
    "filtered_data = tokenized_data.filter(filter_function)\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aeb44b-e661-4d7b-8a56-995d7e115332",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3609976d7ec4b06b2d12bc4b88ac883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/18 shards):   0%|          | 0/125950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741591dbe3f0432590dec7f5d1dbfb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_data = filtered_data.remove_columns([\"input_ids\", \"attention_mask\", \"length\"])\n",
    "filtered_data.save_to_disk('data-rb-chopped-filtered-' + str(max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f049b9-5e8c-4b01-aaa1-bf0b9024d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd1624427ae4458b405136df385f4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 213821\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "filtered_data = load_from_disk('data-rb-chopped-filtered')\n",
    "filtered_data = filtered_data.remove_columns([\"input_ids\", \"attention_mask\", \"length\"])\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae39d89303cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 191\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8a11c2dbf941bfaadb34fc71498c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 191\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='193' max='191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [191/191 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.164000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 1/9 [1:02:36<8:20:49, 3756.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 192\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e778da8ab5b46bda86cdfaa4bce45a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 192\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='194' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 2/9 [2:05:10<7:18:07, 3755.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 193\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f4177b1b414864ad5142772c7720ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 193\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='195' max='193' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [193/193 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.420400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [3:08:24<6:17:15, 3772.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 194\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb5fa38673a45618f5110fc05f7273e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 194\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='196' max='194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [194/194 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.235000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [4:11:34<5:14:57, 3779.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 195\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9297294c5f804dd79a72e1cd4bc3bc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 195\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='197' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [195/195 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.209500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [5:14:43<4:12:11, 3782.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 196\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678d810e380147e8ac094fb2bc08e0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 196\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='198' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [196/196 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.232600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [6:18:00<3:09:23, 3787.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 197\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d37595732e43429278f2c57c5327ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 197\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='199' max='197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [197/197 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.294100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [7:21:33<2:06:31, 3795.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 198\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b293a229021a4504999b253d96736a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 198\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [198/198 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.291300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [8:24:55<1:03:18, 3798.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n",
      "Steps: 199\n",
      "Dataset({\n",
      "    features: ['svg', 'html', 'text'],\n",
      "    num_rows: 213821\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0b3e8130aa416bb49af0606e969edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 20,216 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 199\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='199' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [199/199 00:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>1.244700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [9:28:44<00:00, 3791.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "resume = True\n",
    "# for steps in tqdm(range(0, 200, 1)):\n",
    "for steps in tqdm(range(191, 200, 1)):\n",
    "    print(f\"Steps: {steps}\")\n",
    "\n",
    "    if steps > 0:\n",
    "        trainer = create_trainer(model, tokenizer, filtered_data['train'], steps)\n",
    "        if resume:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "            resume = True\n",
    "        \n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "    results = test_prediction(model, filtered_data['test'], steps)\n",
    "\n",
    "    if results is not None and results['perceptual_loss'] == 0.0:\n",
    "        break\n",
    "\n",
    "    model = FastLanguageModel.for_training(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><div class=\"box red\"></div><div class=\"box green\"></div><div class=\"box blue\"></div></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "      * {\n",
      "          margin: 0;\n",
      "          padding: 0;\n",
      "          box-sizing: border-box;\n",
      "      }\n",
      "\n",
      "       body {\n",
      "          height: 100%;\n",
      "          font-family: Arial, sans-serif;\n",
      "      }\n",
      "\n",
      "      body {\n",
      "          display: flex;\n",
      "          flex-direction: column;\n",
      "          height: 100vh;\n",
      "      }\n",
      "\n",
      "      .box {\n",
      "          flex: 1; \n",
      "          width: 100%;\n",
      "      }\n",
      "\n",
      "      .red {\n",
      "          background-color: red;\n",
      "      }\n",
      "\n",
      "      .green {\n",
      "          background-color: green;\n",
      "      }\n",
      "\n",
      "      .blue {\n",
      "          background-color: blue;\n",
      "      }\n",
      "    \n",
      "</style>\n",
      "Answer of the question is: \n",
      "```\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <title>Design</title>\n",
      "    <meta charset=\"UTF-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "    <meta name=\"format-detection\" content=\"date-time-format=dd-mm-yy\" />\n",
      "    <meta name=\"keywords\" content=\"design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design, web, design,\n"
     ]
    }
   ],
   "source": [
    "test_index = 4\n",
    "text = filtered_data['test'][test_index]['svg']\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(filtered_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n",
      "Similarity: 0.5132264371663787\n",
      "Perceptual loss: 0.6475745012750849\n"
     ]
    }
   ],
   "source": [
    "test_prediction(model, filtered_data['test'], steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065cf71-3f41-4bb8-bf51-4faef98067ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
