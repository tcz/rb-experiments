{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da37334-ae8b-4ea9-aff0-678b628bc08b",
   "metadata": {},
   "source": [
    "# T5 pretraining with new size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fce927-9f44-447c-895f-53a0349ed579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:40:55.608539Z",
     "start_time": "2024-11-05T04:39:36.347698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git@13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision 13493215abceafc1653af88b045120014fb4c1fc) to /tmp/pip-req-build-8_qr8ghf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-8_qr8ghf\n",
      "  Running command git rev-parse -q --verify 'sha^13493215abceafc1653af88b045120014fb4c1fc'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git 13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Running command git checkout -q 13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.0.dev0) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Collecting git+https://github.com/huggingface/accelerate.git@8ade23cc6aec7c3bd3d80fef6378cafaade75bbe\n",
      "  Cloning https://github.com/huggingface/accelerate.git (to revision 8ade23cc6aec7c3bd3d80fef6378cafaade75bbe) to /tmp/pip-req-build-ffmg9ony\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-ffmg9ony\n",
      "  Running command git rev-parse -q --verify 'sha^8ade23cc6aec7c3bd3d80fef6378cafaade75bbe'\n",
      "  Running command git fetch -q https://github.com/huggingface/accelerate.git 8ade23cc6aec7c3bd3d80fef6378cafaade75bbe\n",
      "  Running command git checkout -q 8ade23cc6aec7c3bd3d80fef6378cafaade75bbe\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 8ade23cc6aec7c3bd3d80fef6378cafaade75bbe\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (2.4.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate==1.1.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.1.0.dev0) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate==1.1.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.1.0.dev0) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate==1.1.0.dev0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Collecting git+https://github.com/huggingface/datasets.git@01f91bae037c98f2e05456287bab21470adb8f07\n",
      "  Cloning https://github.com/huggingface/datasets.git (to revision 01f91bae037c98f2e05456287bab21470adb8f07) to /tmp/pip-req-build-01irz7gl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets.git /tmp/pip-req-build-01irz7gl\n",
      "  Running command git rev-parse -q --verify 'sha^01f91bae037c98f2e05456287bab21470adb8f07'\n",
      "  Running command git fetch -q https://github.com/huggingface/datasets.git 01f91bae037c98f2e05456287bab21470adb8f07\n",
      "  Running command git checkout -q 01f91bae037c98f2e05456287bab21470adb8f07\n",
      "  Resolved https://github.com/huggingface/datasets.git to commit 01f91bae037c98f2e05456287bab21470adb8f07\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (2.2.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.1.dev0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.1.dev0) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.1.1.dev0) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets==3.1.1.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.1.1.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.1.1.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.1.1.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.1.1.dev0) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.1.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.1.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.1.dev0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.1.dev0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Collecting git+https://github.com/huggingface/evaluate.git@55f1bc6e072b05c2d9db1589a07e20f38902b1ec\n",
      "  Cloning https://github.com/huggingface/evaluate.git (to revision 55f1bc6e072b05c2d9db1589a07e20f38902b1ec) to /tmp/pip-req-build-utud2hdp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/evaluate.git /tmp/pip-req-build-utud2hdp\n",
      "  Running command git rev-parse -q --verify 'sha^55f1bc6e072b05c2d9db1589a07e20f38902b1ec'\n",
      "  Running command git fetch -q https://github.com/huggingface/evaluate.git 55f1bc6e072b05c2d9db1589a07e20f38902b1ec\n",
      "  Running command git checkout -q 55f1bc6e072b05c2d9db1589a07e20f38902b1ec\n",
      "  Resolved https://github.com/huggingface/evaluate.git to commit 55f1bc6e072b05c2d9db1589a07e20f38902b1ec\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (3.1.1.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (2.2.5)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.4.dev0) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.4.dev0) (24.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.4.dev0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.4.dev0) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.4.dev0) (3.11.18)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.4.dev0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.4.dev0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.4.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.4.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.4.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.4.dev0) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.4.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.4.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.4.dev0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.4.dev0) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.4.dev0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Collecting git+https://github.com/huggingface/safetensors.git@f5839b6aee407652aa3078d91206b618dd84e3c2\n",
      "  Cloning https://github.com/huggingface/safetensors.git (to revision f5839b6aee407652aa3078d91206b618dd84e3c2) to /tmp/pip-req-build-jxcxepg_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/safetensors.git /tmp/pip-req-build-jxcxepg_\n",
      "  Running command git rev-parse -q --verify 'sha^f5839b6aee407652aa3078d91206b618dd84e3c2'\n",
      "  Running command git fetch -q https://github.com/huggingface/safetensors.git f5839b6aee407652aa3078d91206b618dd84e3c2\n",
      "  Running command git checkout -q f5839b6aee407652aa3078d91206b618dd84e3c2\n",
      "  Resolved https://github.com/huggingface/safetensors.git to commit f5839b6aee407652aa3078d91206b618dd84e3c2\n",
      "\u001b[31mERROR: git+https://github.com/huggingface/safetensors.git@f5839b6aee407652aa3078d91206b618dd84e3c2 does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2.2.5)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (5.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: pytest-playwright in /opt/conda/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: playwright>=1.18 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (1.51.0)\n",
      "Requirement already satisfied: pytest<9.0.0,>=6.2.4 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.3.4)\n",
      "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (2.1.0)\n",
      "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.0.4)\n",
      "Requirement already satisfied: pyee<13,>=12 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (12.1.1)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (3.2.1)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.9 in /opt/conda/lib/python3.11/site-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.32.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.11/site-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from pyee<13,>=12->playwright>=1.18->pytest-playwright) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (10.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->torchvision) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: lpips in /opt/conda/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.2.1->lpips) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=0.4.0->lpips) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Installing dependencies...\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
      "fonts-liberation is already the newest version (1:1.07.4-11).\n",
      "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
      "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
      "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
      "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
      "libcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libdbus-glib-1-2 is already the newest version (0.112-2build1).\n",
      "libegl1 is already the newest version (1.4.0-1).\n",
      "libenchant-2-2 is already the newest version (2.3.2-1ubuntu2).\n",
      "libepoxy0 is already the newest version (1.5.10-1).\n",
      "libevdev2 is already the newest version (1.12.1+dfsg-1).\n",
      "libevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\n",
      "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
      "libgles2 is already the newest version (1.4.0-1).\n",
      "libglx0 is already the newest version (1.4.0-1).\n",
      "libgudev-1.0-0 is already the newest version (1:237-2build1).\n",
      "libhyphen0 is already the newest version (2.8.8-7build2).\n",
      "libicu70 is already the newest version (70.1-2).\n",
      "libjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\n",
      "liblcms2-2 is already the newest version (2.12~rc1-2build2).\n",
      "libmanette-0.2-0 is already the newest version (0.2.6-3build1).\n",
      "libopengl0 is already the newest version (1.4.0-1).\n",
      "libopus0 is already the newest version (1.3.1-0.1build2).\n",
      "libpng16-16 is already the newest version (1.6.37-3build5).\n",
      "libproxy1v5 is already the newest version (0.4.17-2).\n",
      "libsecret-1-0 is already the newest version (0.20.5-2).\n",
      "libwoff1 is already the newest version (1.0.2-1build4).\n",
      "libxcb-shm0 is already the newest version (1.14-3ubuntu3).\n",
      "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
      "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
      "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
      "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
      "libxext6 is already the newest version (2:1.3.4-1build1).\n",
      "libxfixes3 is already the newest version (1:6.0.0-1).\n",
      "libxi6 is already the newest version (2:1.8-1build1).\n",
      "libxkbcommon0 is already the newest version (1.4.0-1).\n",
      "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
      "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
      "libxtst6 is already the newest version (2:1.2.3-1build4).\n",
      "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
      "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
      "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
      "fonts-unifont is already the newest version (1:14.0.01-1).\n",
      "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
      "libavif13 is already the newest version (0.9.3-3).\n",
      "libffi7 is already the newest version (3.3-5ubuntu1).\n",
      "libx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\n",
      "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
      "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-plugins-base is already the newest version (1.20.1-1ubuntu0.4).\n",
      "gstreamer1.0-plugins-good is already the newest version (1.20.3-0ubuntu1.3).\n",
      "libatomic1 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
      "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
      "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
      "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
      "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
      "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
      "libgdk-pixbuf-2.0-0 is already the newest version (2.42.8+dfsg-1ubuntu0.3).\n",
      "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
      "libgstreamer-gl1.0-0 is already the newest version (1.20.1-1ubuntu0.4).\n",
      "libgstreamer-plugins-base1.0-0 is already the newest version (1.20.1-1ubuntu0.4).\n",
      "libgstreamer1.0-0 is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\n",
      "libgtk-4-1 is already the newest version (4.6.9+ds-0ubuntu0.22.04.2).\n",
      "libharfbuzz-icu0 is already the newest version (2.7.4-1ubuntu3.2).\n",
      "libharfbuzz0b is already the newest version (2.7.4-1ubuntu3.2).\n",
      "libnotify4 is already the newest version (0.7.9-3ubuntu5.22.04.1).\n",
      "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
      "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
      "libopenjp2-7 is already the newest version (2.4.0-6ubuntu0.3).\n",
      "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\n",
      "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libxml2 is already the newest version (2.9.13+dfsg-1ubuntu0.6).\n",
      "libxslt1.1 is already the newest version (1.1.34-4ubuntu0.22.04.3).\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-libav is already the newest version (1.20.3-0ubuntu1).\n",
      "gstreamer1.0-plugins-bad is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libsoup-3.0-0 is already the newest version (3.0.7-0ubuntu1).\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.8)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.2.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (6.30.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (69.5.1)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "!pip install -U git+https://github.com/huggingface/transformers.git@13493215abceafc1653af88b045120014fb4c1fc\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git@8ade23cc6aec7c3bd3d80fef6378cafaade75bbe\n",
    "!pip install -U git+https://github.com/huggingface/datasets.git@01f91bae037c98f2e05456287bab21470adb8f07\n",
    "!pip install -U git+https://github.com/huggingface/evaluate.git@55f1bc6e072b05c2d9db1589a07e20f38902b1ec\n",
    "!pip install -U git+https://github.com/huggingface/safetensors.git@f5839b6aee407652aa3078d91206b618dd84e3c2\n",
    "\n",
    "!pip install sacrebleu\n",
    "!pip install pytest-playwright\n",
    "!playwright install\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install torchvision\n",
    "!pip install lpips\n",
    "\n",
    "!playwright install-deps  \n",
    "\n",
    "!pip install -U numpy\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad76b366440f2ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-06T10:37:04.434307Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-12build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
      "--2025-04-23 11:41:31--  https://www.dropbox.com/scl/fi/t3yni1506szbqgzd50zsk/data-rb-size2.zip?rlkey=ko2kdesucccnk732hga4i94yv&dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.13.18, 2620:100:6057:18::a27d:d12\n",
      "connected. to www.dropbox.com (www.dropbox.com)|162.125.13.18|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com/cd/0/inline/CoUwUAY0ETYbpQFkbHY46qgyltHRjRpBELlda99yqtiflJH2fVpjK6S0Z-HYmh40PnHZvsKAxNzHje2yRKIFgQ7bcYFLpZWuHvJwlJEdNf-0CXnICNmUoAb0jZf3cjqfiOI/file?dl=1# [following]\n",
      "--2025-04-23 11:41:32--  https://uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com/cd/0/inline/CoUwUAY0ETYbpQFkbHY46qgyltHRjRpBELlda99yqtiflJH2fVpjK6S0Z-HYmh40PnHZvsKAxNzHje2yRKIFgQ7bcYFLpZWuHvJwlJEdNf-0CXnICNmUoAb0jZf3cjqfiOI/file?dl=1\n",
      "Resolving uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com (uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6057:15::a27d:d0f\n",
      "connected. to uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com (uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com)|162.125.13.15|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/CoWHVUm_WKi23p9HKOerpNVbHFgxzMxHjyBjaljwQLaWOA61IA18gjEmacqTuI7bh8ERq62BAhD-Y4EhHhGI6yO6RBX5ACrn7R5qoGSrOkdmWnZ7up4TnrzgoU8XqEW8FfboTvo43zeXZt_g6w_s3KrOg2e4SvtEgiMZg5FgvqVG0Q0qEV_eiXRPWyJ8O8R9QL8o2t9Dlp08PG0uABrk4Hob1BkHF5MaZ_PiiSvt2Z6ksWzYiPCE-S0fO-QHio3tqhSBj7HiqWmrcASyoAQJTbJ_1uZJ3mVT2i2v9KVMQssdgzAKL9vbiatES-ZRvdp4AOpPaFVeJClK_kOox83Fsht2gZAn6ZlcXaeo77xthwlbJA/file?dl=1 [following]\n",
      "--2025-04-23 11:41:33--  https://uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com/cd/0/inline2/CoWHVUm_WKi23p9HKOerpNVbHFgxzMxHjyBjaljwQLaWOA61IA18gjEmacqTuI7bh8ERq62BAhD-Y4EhHhGI6yO6RBX5ACrn7R5qoGSrOkdmWnZ7up4TnrzgoU8XqEW8FfboTvo43zeXZt_g6w_s3KrOg2e4SvtEgiMZg5FgvqVG0Q0qEV_eiXRPWyJ8O8R9QL8o2t9Dlp08PG0uABrk4Hob1BkHF5MaZ_PiiSvt2Z6ksWzYiPCE-S0fO-QHio3tqhSBj7HiqWmrcASyoAQJTbJ_1uZJ3mVT2i2v9KVMQssdgzAKL9vbiatES-ZRvdp4AOpPaFVeJClK_kOox83Fsht2gZAn6ZlcXaeo77xthwlbJA/file?dl=1\n",
      "Reusing existing connection to uc0c6bb69d23327975481a9e77ef.dl.dropboxusercontent.com:443.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 1739021 (1.7M) [application/binary]\n",
      "Saving to: ‘model.zip’\n",
      "\n",
      "model.zip           100%[===================>]   1.66M  1.75MB/s    in 0.9s    \n",
      "\n",
      "2025-04-23 11:41:34 (1.75 MB/s) - ‘model.zip’ saved [1739021/1739021]\n",
      "\n",
      "Archive:  model.zip\n",
      "  inflating: data-rb-size/state.json  \n",
      "  inflating: data-rb-size/dataset_info.json  \n",
      "  inflating: data-rb-size/data-00000-of-00001.arrow  \n"
     ]
    }
   ],
   "source": [
    "!apt install zip -y\n",
    "!rm -rf data-rb-size\n",
    "!mkdir -p data-rb-size\n",
    "!wget \"https://www.dropbox.com/scl/fi/t3yni1506szbqgzd50zsk/data-rb-size2.zip?rlkey=ko2kdesucccnk732hga4i94yv&dl=1\" -O model.zip\n",
    "!unzip model.zip -d data-rb-size\n",
    "\n",
    "!mkdir -p data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce2ce9117ee29ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:10:08.863278Z",
     "start_time": "2024-10-16T02:10:08.630248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['svg', 'html'],\n",
      "        num_rows: 99685\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['svg', 'html'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['svg', 'html'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "validation_size = 4\n",
    "test_size = 100\n",
    "\n",
    "dataset = load_from_disk('data-rb-size')\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=test_size/len(dataset))\n",
    "train_valid_split = train_test_split['train'].train_test_split(test_size=validation_size/len(dataset))\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_valid_split[\"train\"],\n",
    "    \"valid\": train_valid_split[\"test\"],\n",
    "    \"test\": train_test_split[\"test\"],\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d70d196-34fa-4aa3-980b-ee55ad689ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svg': '<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"div1 style1\"><g data-tag=\"div\" id=\"div1\" data-z-index=\"auto\" data-stacking-context=\"true\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"0.15625\" height=\"852\" x=\"0\" y=\"0\" fill=\"rgb(0, 0, 0)\"/></g></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>', 'html': '<body><div></div></body>\\n\\n<style>\\n\\n\\n        body {\\n            margin: 0;\\n        }\\n\\n        div {\\n            background-color: black;\\n            position: absolute;\\n            height: 100vh;\\n            width: 0.043%;\\n            top: 0;\\n            left: 0;\\n        }\\n\\n\\n</style>'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b75278ac780233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T03:21:09.213457Z",
     "start_time": "2024-10-21T03:21:09.164204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "new_words = ['<', '>', '{', '}', '<body>', '<div>', '</div>', '<style>', '</style>', '</body>']\n",
    "tokenizer.add_tokens(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800a33e8-fea0-45cf-8bd6-6298946ef9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No unknown tokens found in the SVG.\n",
      "No unknown tokens found in the HTML.\n"
     ]
    }
   ],
   "source": [
    "tokenized_output = tokenizer.encode(dataset['train'][0]['svg'], add_special_tokens=False)\n",
    "unk_token_id = tokenizer.unk_token_id\n",
    "if unk_token_id in tokenized_output:\n",
    "    print(\"Alert: The tokenized SVG contains unknown tokens.\")\n",
    "else:\n",
    "    print(\"No unknown tokens found in the SVG.\")\n",
    "\n",
    "tokenized_output = tokenizer.encode(dataset['train'][0]['html'], add_special_tokens=False)\n",
    "unk_token_id = tokenizer.unk_token_id\n",
    "if unk_token_id in tokenized_output:\n",
    "    print(\"Alert: The tokenized HTML contains unknown tokens.\")\n",
    "else:\n",
    "    print(\"No unknown tokens found in the HTML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fb1f810bdc58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><div></div></body><style> body{ margin: 0;} div{ background-color: black; position: absolute; height: 100vh; width: 0.043%; top: 0; left: 0;}</style>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(dataset['train'][0]['html'], add_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee6756eef09e4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T07:01:04.027007Z",
     "start_time": "2024-10-17T06:31:33.349933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503eae1f84d94806a044995f99a7befa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bd3f97f57f4090b83d93c7a45852b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a184e5d9c114fceb65d4e5ce9066a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d760616d87144e03ba40cc51f85a41df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/99685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc37c687df34513a66e1cce047a7fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c82030af774b9c9ffde4ae2f27c5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c48cebe8ca64faf9579a5b86425cf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99685 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d862b31b8f0e455faac23790913dcc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd47dbabfb024f41b18cc1f5e9429248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'input_length', 'labels', 'label_length'],\n",
      "        num_rows: 99685\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'input_length', 'labels', 'label_length'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'input_length', 'labels', 'label_length'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "def get_token_lengths(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['svg'],\n",
    "        truncation=False,  # Don't truncate yet\n",
    "        padding=False,     # Don't pad yet\n",
    "        return_length=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples['html'],\n",
    "        truncation=False,\n",
    "        padding=False,\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    inputs[\"input_length\"] = inputs[\"length\"]\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    inputs[\"label_length\"] = labels[\"length\"]\n",
    "\n",
    "    inputs.pop(\"length\", None)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = dataset.map(get_token_lengths, batched=True)\n",
    "\n",
    "def filter_function(example):\n",
    "    return example['input_length'] <= MAX_SEQUENCE_LENGTH and example['label_length'] <= MAX_SEQUENCE_LENGTH\n",
    "\n",
    "filtered_data = tokenized_data.filter(filter_function)\n",
    "\n",
    "def tokenize_examples(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['svg'],\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples['html'],\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    labels = labels['input_ids']\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    inputs[\"labels\"] = labels\n",
    "    \n",
    "\n",
    "    return inputs\n",
    "\n",
    "filtered_data = filtered_data.map(get_token_lengths, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384b70a1fd6cda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "import shutil\n",
    "\n",
    "VIEWPORT_SIZES = {\n",
    "    'DESKTOP': {'width': 1440, 'height': 900},\n",
    "    'TABLET': {'width': 834, 'height': 1210},\n",
    "    'MOBILE': {'width': 393, 'height': 852},\n",
    "}\n",
    "\n",
    "VIEWPORTS = ['MOBILE']\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def create_compute_metrics(trainer, save_best_model_dir = None):\n",
    "    best_perceptual_loss = None\n",
    "\n",
    "    def compute_metrics(eval_predictions, to_tensorboard = True):\n",
    "        nonlocal best_perceptual_loss\n",
    "\n",
    "        predictions, labels = eval_predictions\n",
    "        \n",
    "        if isinstance(predictions, tuple):\n",
    "            predictions = predictions[0]\n",
    "\n",
    "        decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        decoded_predictions, decoded_labels = postprocess_text(decoded_predictions, decoded_labels)\n",
    "    \n",
    "        similarity_scores = []\n",
    "        perceptual_losses = []\n",
    "        index = 1\n",
    "        for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "            if to_tensorboard:\n",
    "                add_text_to_tensorboard(f'valid_{index}_label_text', trainer.state.global_step, label[0])\n",
    "                add_text_to_tensorboard(f'valid_{index}_prediction_text', trainer.state.global_step, prediction)\n",
    "\n",
    "            for viewport in VIEWPORTS:\n",
    "            \n",
    "                metrics = calculate_metrics(prediction, label[0],\n",
    "                                        VIEWPORT_SIZES[viewport]['width'], VIEWPORT_SIZES[viewport]['height'])\n",
    "\n",
    "                if metrics is not None:\n",
    "                    similarity_scores.append(metrics['similarity'])\n",
    "                    perceptual_losses.append(metrics['perceptual_loss'])\n",
    "\n",
    "                    if to_tensorboard:\n",
    "                        add_image_to_tensorboard(f'valid_{index}_expectation_' + viewport.lower(), trainer.state.global_step, metrics['expected_screenshot_path'])\n",
    "                        add_image_to_tensorboard(f'valid_{index}_prediction_' + viewport.lower(), trainer.state.global_step, metrics['predicted_screenshot_path'])\n",
    "            \n",
    "            index += 1\n",
    "\n",
    "\n",
    "        result = {\n",
    "            'similarity': float(np.mean(similarity_scores)),\n",
    "            'perceptual_loss': float(np.mean(perceptual_losses)),\n",
    "        }\n",
    "\n",
    "        if save_best_model_dir is not None:\n",
    "            if best_perceptual_loss is None or result['perceptual_loss'] < best_perceptual_loss:\n",
    "                if os.path.exists(save_best_model_dir):\n",
    "                    shutil.rmtree(save_best_model_dir)\n",
    "                trainer.save_model(save_best_model_dir)\n",
    "                tokenizer.save_pretrained(save_best_model_dir)\n",
    "                with open(os.path.join(save_best_model_dir, 'best_results.txt'), 'w') as f:\n",
    "                    f.write(str(result) + '\\nStep: ' + str(trainer.state.global_step))\n",
    "\n",
    "                best_perceptual_loss = result['perceptual_loss']\n",
    "    \n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result\n",
    "    \n",
    "    return compute_metrics\n",
    "\n",
    "def eval_outside_of_training(model, dataset, to_tensorboard = False, step = None):\n",
    "    def pad_to_matrix(seqs, pad_value=0):\n",
    "        max_len = max(len(s) for s in seqs)\n",
    "        matrix  = np.full((len(seqs), max_len), pad_value, dtype=np.int64)\n",
    "        for i, s in enumerate(seqs):\n",
    "            matrix[i, :len(s)] = s                 # left-align, pad on the right\n",
    "        return matrix\n",
    "    \n",
    "    model.eval()\n",
    "    model.to('cuda:0')\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for row in dataset:\n",
    "        inputs = tokenizer(row['svg'], return_tensors=\"pt\").input_ids\n",
    "        labels.append(tokenizer(row['html'], return_tensors=\"pt\").input_ids)\n",
    "        inputs = inputs.to('cuda:0')\n",
    "        outputs = model.generate(inputs)\n",
    "        predictions.append(outputs[0])\n",
    "\n",
    "    mock_trainer = SimpleNamespace(state=SimpleNamespace(global_step=step))\n",
    "    compute_metrics = create_compute_metrics(mock_trainer)\n",
    "    return compute_metrics((\n",
    "            pad_to_matrix([t.cpu().numpy() for t in predictions]), \n",
    "            pad_to_matrix([t.squeeze(0).cpu().numpy() for t in labels])\n",
    "        ), to_tensorboard=to_tensorboard)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b85759-0b3e-4d8e-83df-5d5592342906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T00:15:54.750802Z",
     "start_time": "2024-10-08T00:15:54.748356Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1aa323-b581-47ae-ad5d-76432876ec60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T00:17:08.459741Z",
     "start_time": "2024-10-08T00:17:05.043094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32109, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"google-t5/t5-small\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    decoder_start_token_id = tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b220913c2a31da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T06:54:24.215945Z",
     "start_time": "2024-10-09T06:54:24.196547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"max_new_tokens\": 512,\n",
       "  \"pad_token_id\": 0\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig.from_model_config(model.config)\n",
    "generation_config._from_model_config = False\n",
    "generation_config.max_new_tokens = 512\n",
    "\n",
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94ab3b8-6735-43d2-a6dc-5ef792af3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_output_dir = f\"model-{timestamp}\"\n",
    "log_dir = f'{model_output_dir}/runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db770b6b1fc3a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eval_outside_of_training(model, dataset[\"valid\"], True, 0)\n",
    "writer = SummaryWriter(log_dir=log_dir)   # or reuse the one you have\n",
    "for k, v in results.items():\n",
    "    writer.add_scalar(f\"eval/{k}\", v, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df99189-0f2a-485e-b066-2265a5dbf5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T09:15:17.030472Z",
     "start_time": "2024-10-07T09:15:16.955982Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62310' max='62310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62310/62310 1:14:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Perceptual Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.436081</td>\n",
       "      <td>0.618200</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>21.837800</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.390900</td>\n",
       "      <td>0.397944</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>21.213000</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.367455</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>21.488000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.359702</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>20.792000</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.336147</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>20.879000</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.311565</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.546400</td>\n",
       "      <td>21.658200</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.277318</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>21.197100</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.274606</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>20.163100</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.265456</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>20.641900</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.259163</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>22.569200</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.243365</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.510900</td>\n",
       "      <td>22.642100</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.234532</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>22.439500</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.222665</td>\n",
       "      <td>0.767900</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>23.102500</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.220194</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>23.368700</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.212180</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>20.929100</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.211397</td>\n",
       "      <td>0.794600</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>21.658500</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.211306</td>\n",
       "      <td>0.790500</td>\n",
       "      <td>0.271100</td>\n",
       "      <td>21.794300</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.209321</td>\n",
       "      <td>0.805300</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>23.936300</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.214654</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>23.802700</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.197634</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>24.485000</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.196586</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>24.105300</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.214591</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>22.965600</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.218610</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>23.361800</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.199977</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>23.579700</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.208572</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>24.691300</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>21.756100</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.986100</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>22.124200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.190832</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>23.645700</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.205143</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>22.760200</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>22.811300</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.197576</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>22.031400</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.191902</td>\n",
       "      <td>0.807800</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>22.730400</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.177659</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>22.824000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.171528</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>22.769900</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.170283</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>22.825900</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.188909</td>\n",
       "      <td>0.629600</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>22.686100</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.177978</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>21.735300</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.169771</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>20.767700</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>21.543000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.166196</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>23.213800</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.171662</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>22.621100</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.156855</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>23.801500</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.157150</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>22.093200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.156978</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>23.349400</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.159153</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>24.452200</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.177255</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>20.434600</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.168171</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>22.541400</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.171581</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>22.291600</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.163638</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>23.029100</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.167621</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>22.309600</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.166353</td>\n",
       "      <td>0.872300</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>21.501500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>21.029500</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.173910</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>23.144300</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.175334</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>21.433300</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.171791</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>23.288500</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.176173</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>22.925200</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.188932</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>23.688500</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.174246</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>23.199300</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.174670</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>24.666700</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.188329</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>22.403800</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>20.794600</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.139500</td>\n",
       "      <td>0.188174</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>22.033500</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62310, training_loss=0.19457989331903397, metrics={'train_runtime': 4486.9705, 'train_samples_per_second': 222.165, 'train_steps_per_second': 13.887, 'total_flos': 1.0362681111271834e+17, 'train_loss': 0.19457989331903397, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import os\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_output_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps=16,\n",
    "    # gradient_checkpointing=True,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=25,\n",
    "    logging_dir=log_dir,\n",
    "    predict_with_generate=True,\n",
    "    # load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=filtered_data[\"train\"],\n",
    "    eval_dataset=filtered_data[\"valid\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=None,\n",
    ")\n",
    "\n",
    "trainer.compute_metrics = create_compute_metrics(trainer, os.path.join(model_output_dir, \"best\"))\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67966342-5779-413b-991f-85890f04ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-2025-04-23_14-35-22/final/tokenizer_config.json',\n",
       " 'model-2025-04-23_14-35-22/final/special_tokens_map.json',\n",
       " 'model-2025-04-23_14-35-22/final/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "trainer.save_model(os.path.join(model_output_dir, \"final\"))\n",
    "tokenizer.save_pretrained(os.path.join(model_output_dir, \"final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3651bec92cad0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><div></div></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            margin: 0;\n",
      "        }\n",
      "\n",
      "        div {\n",
      "            background-color: black;\n",
      "            position: absolute;\n",
      "            height: 100vh;\n",
      "            width: 86.328%;\n",
      "            top: 0;\n",
      "            left: 0;\n",
      "        }\n",
      "\n",
      "\n",
      "</style>\n",
      "<body><div></div></body><style> body{ margin: 0;} div{ background-color: black; position: absolute; height: 100vh; width: 86.932%; top: 0; left: 0;}</style>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "text = dataset['test'][0]['svg']\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "inputs = inputs.to('cuda:0')\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(os.path.join(model_output_dir, \"best\"))\n",
    "model.to('cuda:0')\n",
    "model.generation_config = generation_config\n",
    "\n",
    "outputs = model.generate(inputs)\n",
    "# outputs = model.generate(inputs, max_new_tokens=16_384, do_sample=True, top_k=30, top_p=0.95)\n",
    "\n",
    "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dataset['test'][0]['html'])\n",
    "print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42f4bddcc5a3667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'similarity': 0.8754, 'perceptual_loss': 0.1526}\n"
     ]
    }
   ],
   "source": [
    "test_results = eval_outside_of_training(model, dataset[\"test\"], False)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222215f8-9eae-461e-90e1-2b47494837f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
