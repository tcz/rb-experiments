{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 90B fine tuning with large data set\n",
    "\n",
    "2025-03-14 11:40\n",
    "\n",
    "90B big run with large data set, 12000 max sequence length.\n",
    "Stopped early for two reasons:\n",
    "- For some reason the validation was done on the test data set, not the validation one\n",
    "- Realized that utils doesn't actually set the viewport size. This is not really a problem for the simple synthetic data, but for real-world data it matters because the SVG input in this data set is mobile. This will need to be fixed for other runs, e.g. longt5, lower parameter count llama runs, etc.\n",
    "\n",
    "What I've seen:\n",
    "- Perceptual loss was pretty low to start with. This makes sense since we are talking about a \"smarter\" model. Note that the perceptual loss here was calculated on the train dataset, not the validation dataset.\n",
    "- Perceptual loss decreased after 50 and 100 steps, but went slightly back up after 150. I might want to also test this more frequently, e.g. 25\n",
    "- Loss seemed to taper off a little bit after 150 steps.\n",
    "- Did about 0.5 epoch\n",
    "- There are a LOT of not-found, internal server error, etc pages. This might require cleanup\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer, AutoTokenizer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, FastVisionModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e835c55e-7bae-40a1-97af-64c78ef0e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\u001B[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    " \n",
    "login(\n",
    "  token=\"<HF_API_KEY_REMOVED>\", \n",
    "  add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 12000\n",
    "\n",
    "def load_model():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_compute_dtype=torch.float16,  \n",
    "        bnb_4bit_use_double_quant=True,  \n",
    "        bnb_4bit_quant_type=\"nf4\", \n",
    "    )\n",
    "\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name=\"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        quantization_config=bnb_config, \n",
    "        device_map=\"auto\" \n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\")\n",
    "    \n",
    "    model = FastVisionModel.get_peft_model(\n",
    "        model,\n",
    "\n",
    "        finetune_vision_layers     = False,\n",
    "        finetune_language_layers   = True,\n",
    "        finetune_attention_modules = True,\n",
    "        finetune_mlp_modules       = True,\n",
    "        \n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "        use_rslora=True,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state = 32,\n",
    "        loftq_config = None,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167425bb45a12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, training_data, max_steps):\n",
    "    # def collate_fn(examples):\n",
    "    #     processed_examples = [example['text'] for example in examples]\n",
    "    \n",
    "    #     batch = tokenizer(\n",
    "    #         text=processed_examples, \n",
    "    #         images=None, \n",
    "    #         return_tensors=\"pt\", \n",
    "    #         padding=True\n",
    "    #     )\n",
    "    \n",
    "    #     labels = batch[\"input_ids\"].clone()\n",
    "    #     labels[labels == tokenizer.tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    #     batch[\"labels\"] = labels\n",
    "    \n",
    "    #     return batch\n",
    "    \n",
    "    # 2 alternative = use Out of the box data collator\n",
    "    from transformers import DataCollatorForLanguageModeling\n",
    "    collate_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    \n",
    "    training_arguments = UnslothTrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        embedding_learning_rate = 3e-5,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 128,\n",
    "        num_train_epochs=40,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        # max_steps=max_steps,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=150,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    if max_steps is not None:\n",
    "        training_arguments.max_steps = max_steps\n",
    "    \n",
    "    return UnslothTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=training_data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=10,\n",
    "        packing=True,\n",
    "        args=training_arguments,\n",
    "        data_collator = collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label)\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    results = {\n",
    "        \"similarity\": float(np.mean(similarity_scores)),\n",
    "        \"perceptual_loss\": float(np.mean(perceptual_losses)),\n",
    "    }\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', results['similarity'], steps)\n",
    "    writer.add_scalar('perceptual_loss', results['perceptual_loss'], steps)\n",
    "    \n",
    "    print(\"Similarity:\", results['similarity'])\n",
    "    print(\"Perceptual loss:\", results['perceptual_loss'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    return compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9436b4-22de-4180-a7d6-9aad00934c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8b3c6163163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install zip -y\n",
    "!rm -rf data-rb-large\n",
    "!mkdir -p data-rb-large\n",
    "!wget \"https://www.dropbox.com/scl/fi/868hi141d4hrzwntxxih3/data-rb-large-with-tokenizer.zip?rlkey=md8iq2htminafzqcol3tzfbva&dl=1\" -O model.zip\n",
    "!unzip model.zip -d data-rb-large\n",
    "\n",
    "!rm -rf data-rb-validate\n",
    "!mkdir -p data-rb-validate\n",
    "!wget \"https://www.dropbox.com/scl/fi/5szml8y5l248mcabj9rqg/verify-dataset.zip?rlkey=se33rwtxgngn0ts1i0pc8f6wk&st=1d68x9zt&dl=1\" -O validate.zip\n",
    "!unzip validate.zip -d data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3d9ae5b9b9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "dataset = load_from_disk('data-rb-large')\n",
    "visual_validation_dataset = load_from_disk('data-rb-validate')\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=100/len(dataset)) \n",
    "train_dataset = train_test_split[\"train\"]\n",
    "temp_dataset = train_test_split[\"test\"]\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"valid\": visual_validation_dataset,\n",
    "    \"test\": train_test_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c684fe8-032a-4c0d-b9ba-cb652ded3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bf3a2cdcc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.3: Fast Mllama vision patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.111 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca3e09de9414f798e205be06d7d216a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.vision_model.transformer` require gradients\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model()\n",
    "\n",
    "data_prompt = \"\"\"Your job is to take an SVG file of a web design and convert it into a pixel-perfect HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"svg\"]\n",
    "    outputs      = examples[\"html\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57abcb9-04a6-4ad6-91af-7fd09e7118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b25f6-18b9-4ac9-bad7-2d6ccfe2355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98a5487-c348-4ed3-ad6e-f8178cd5179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c83479923e45668059c0d5b7f0ac4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "training_data = load_from_disk('data-rb-large-filtered-50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8289ee3c-34eb-4ca3-b69b-2e7a2828a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed57b26c23742179a36923370f7ca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/293102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a288fc271745bca740eace85ae5404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7aaae1edc4babb5471517af3ddc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa52258f611044e792ffc8af2df67fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/293102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ae241019c445b0bc92ca167c2299b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb208629c347809df409bbee10573d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 100502\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 23\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def get_token_lengths(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=False,  # Don't truncate yet\n",
    "        padding=False,     # Don't pad yet\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = training_data.map(get_token_lengths, batched=True)\n",
    "\n",
    "def filter_function(example):\n",
    "    return example['length'] <= max_seq_length\n",
    "\n",
    "filtered_data = tokenized_data.filter(filter_function)\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90aeb44b-e661-4d7b-8a56-995d7e115332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47722e436fe74b749c5d90633b25f152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/23 shards):   0%|          | 0/100502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e874f02e5884918ab99ed704713eceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5457984b964730b412b58243589594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_data = filtered_data.remove_columns([\"input_ids\", \"attention_mask\", \"length\"])\n",
    "filtered_data.save_to_disk('data-rb-large-filtered-' + str(max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f049b9-5e8c-4b01-aaa1-bf0b9024d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5b4c1c16634a1f96cc83e31662e3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100502\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 23\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "filtered_data = load_from_disk('data-rb-large-filtered-' + str(max_seq_length))\n",
    "\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae39d89303cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 0\n",
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1/30 [45:32<22:00:46, 2732.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8855191506538916\n",
      "Perceptual loss: 0.3974166616453263\n",
      "Steps: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d63ea1d147c4ca293951aa58e488f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,831 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 50\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "ðŸ¦¥ Unsloth needs about 1-3 minutes to load everything - please wait!\n",
      "Unsloth: Not an error, but MllamaForConditionalGeneration does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 33:54:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.725300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.645400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.670800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.714500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.618800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.638400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.545200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.549200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.452200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.483100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 2/30 [40:20:11<660:36:54, 84936.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9004705103797049\n",
      "Perceptual loss: 0.28162423227711214\n",
      "Steps: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebd4dc1e9244bce8c9466bf3a190f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,831 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 100\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "ðŸ¦¥ Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 33:57:40, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.445800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.413400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.343600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.329400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.279700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.267100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.250700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.247500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 3/30 [79:15:18<825:57:52, 110128.60s/it]max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9201804714662672\n",
      "Perceptual loss: 0.24637610698118806\n",
      "Steps: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,831 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 150\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "ðŸ¦¥ Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 34:01:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.246800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.227700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.229600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.207300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 4/30 [117:12:44<870:58:45, 120597.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8977920259907191\n",
      "Perceptual loss: 0.24862502679309767\n",
      "Steps: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,831 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 200\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "ðŸ¦¥ Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='181' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/200 20:09:07 < 13:12:11, 0.00 it/s, Epoch 0.50/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.209400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.203300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.190900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.219200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.211700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.199400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "resume = False\n",
    "\n",
    "for steps in tqdm(range(0, 1500, 50)):\n",
    "    print(f\"Steps: {steps}\")\n",
    "\n",
    "    if steps > 0:\n",
    "        trainer = create_trainer(model, tokenizer, filtered_data['train'], steps)\n",
    "        if resume:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "            resume = True\n",
    "        \n",
    "    model = FastVisionModel.for_inference(model)\n",
    "\n",
    "    # results = test_prediction(model, filtered_data['valid'], steps)\n",
    "    results = test_prediction(model, filtered_data['test'], steps)\n",
    "\n",
    "    if results is not None and results['perceptual_loss'] == 0.0:\n",
    "        break\n",
    "\n",
    "    model = FastVisionModel.for_training(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"top bottom style1\"><g data-tag=\"div\" id=\"top\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"top-left top-right\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"366.359375\" x=\"0\" y=\"0\" fill=\"rgb(128, 5, 118)\"/></g><g data-tag=\"div\" id=\"top-left\" data-z-index=\"auto\" data-stacking-context=\"true\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"200.421875\" height=\"366.359375\" x=\"0\" y=\"0\" fill=\"rgb(113, 7, 188)\"/></g><text color=\"rgb(184, 124, 151)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"29px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(184, 124, 151)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(184, 124, 151)\"><tspan xml:space=\"preserve\" x=\"0\" y=\"32\" textLength=\"103.140625\" lengthAdjust=\"spacingAndGlyphs\">BEGAN</tspan></text></g><g data-tag=\"div\" id=\"top-right\" data-z-index=\"auto\" data-stacking-context=\"true\"><text color=\"rgb(37, 86, 73)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"29px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(37, 86, 73)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(37, 86, 73)\"><tspan xml:space=\"preserve\" x=\"200.421875\" y=\"32\" textLength=\"101.5\" lengthAdjust=\"spacingAndGlyphs\">FUNNY</tspan></text></g></g><g data-tag=\"div\" id=\"bottom\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"bottom-left bottom-right\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"485.640625\" x=\"0\" y=\"366.359375\" fill=\"rgb(123, 190, 154)\"/></g><g data-tag=\"div\" id=\"bottom-left\" data-z-index=\"auto\" data-stacking-context=\"true\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"164\" height=\"485.640625\" x=\"0\" y=\"366.359375\" fill=\"rgb(173, 203, 187)\"/></g><text color=\"rgb(85, 235, 21)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"26.88px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(85, 235, 21)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(85, 235, 21)\"><tspan xml:space=\"preserve\" x=\"0\" y=\"396.359375\" textLength=\"94.09375\" lengthAdjust=\"spacingAndGlyphs\">CHOSE</tspan></text></g><g data-tag=\"div\" id=\"bottom-right\" data-z-index=\"auto\" data-stacking-context=\"true\"><text color=\"rgb(142, 139, 140)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"21.3333px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(142, 139, 140)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(142, 139, 140)\"><tspan xml:space=\"preserve\" x=\"164\" y=\"390.359375\" textLength=\"77.453125\" lengthAdjust=\"spacingAndGlyphs\">HARRY</tspan></text></g></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>\n",
      "<body><div id=\"top\"><div id=\"top-left\">BEGAN</div><div id=\"top-right\">FUNNY</div></div><div id=\"bottom\"><div id=\"bottom-left\">CHOSE</div><div id=\"bottom-right\">HARRY</div></div></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            margin: 0;\n",
      "            display: flex;\n",
      "            flex-direction: column;\n",
      "            min-height: 100vh;\n",
      "            font-weight: bold;\n",
      "        }\n",
      "\n",
      "        #top {\n",
      "            background-color: #800576;\n",
      "            flex-basis: 43vh;\n",
      "            flex-grow: 0;\n",
      "            flex-shrink: 0;\n",
      "            color: #255649;\n",
      "            font-size: 29px;\n",
      "        }\n",
      "\n",
      "        #bottom {\n",
      "            background-color: #7bbe9a;\n",
      "            flex: 1 1 auto;\n",
      "            color: #8e8b8c;\n",
      "            font-size: 16pt;\n",
      "        }\n",
      "\n",
      "        #top, #bottom {\n",
      "            display: flex;\n",
      "        }\n",
      "\n",
      "        #top-left {\n",
      "            flex-basis: 51vw;\n",
      "            background: #7107bc;\n",
      "            color: #b87c97;\n",
      "            font-size: 1em;\n",
      "        }\n",
      "\n",
      "        #bottom-left {\n",
      "            flex-basis: 164px;\n",
      "            background: #adcbbb;\n",
      "            color: #55eb15;\n",
      "            font-size: 126%;\n",
      "        }\n",
      "\n",
      "\n",
      "</style>\n",
      "Answer of the question is: \n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Pixel-Perfect HTML and CSS Markup</title>\n",
      "    <style>\n",
      "        /* Global Styles */\n",
      "        * {\n",
      "            box-sizing: border-box;\n",
      "            margin: 0;\n",
      "            padding: 0;\n",
      "        }\n",
      "        \n",
      "        /* Top Section Styles */\n",
      "        #top {\n",
      "            width: 393px;\n",
      "            height: 366.359375px;\n",
      "            background-color: rgb(128, 5, 118);\n",
      "        }\n",
      "        \n",
      "        #top-left {\n",
      "            width: 200.421875px;\n",
      "            height: 366.359375px;\n",
      "            background-color: rgb(113, 7, 188);\n",
      "            float: left;\n",
      "        }\n",
      "        \n",
      "        #top-left > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 29px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(184, 124, 151);\n",
      "            position: absolute;\n",
      "            top: 32px;\n",
      "            left: 0;\n",
      "        }\n",
      "        \n",
      "        #top-right {\n",
      "            float: right;\n",
      "        }\n",
      "        \n",
      "        #top-right > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 29px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(37, 86, 73);\n",
      "            position: absolute;\n",
      "            top: 32px;\n",
      "            right: 0;\n",
      "        }\n",
      "        \n",
      "        /* Bottom Section Styles */\n",
      "        #bottom {\n",
      "            width: 393px;\n",
      "            height: 485.640625px;\n",
      "            background-color: rgb(123, 190, 154);\n",
      "            clear: both;\n",
      "        }\n",
      "        \n",
      "        #bottom-left {\n",
      "            width: 164px;\n",
      "            height: 485.640625px;\n",
      "            background-color: rgb(173, 203, 187);\n",
      "            float: left;\n",
      "        }\n",
      "        \n",
      "        #bottom-left > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 26.88px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(85, 235, 21);\n",
      "            position: absolute;\n",
      "            top: 396.359375px;\n",
      "            left: 0;\n",
      "        }\n",
      "        \n",
      "        #bottom-right {\n",
      "            float: right;\n",
      "        }\n",
      "        \n",
      "        #bottom-right > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 21.3333px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(142, 139, 140);\n",
      "            position: absolute;\n",
      "            top: 390.359375px;\n",
      "            right: 0;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"top\">\n",
      "        <div id=\"top-left\">\n",
      "            <span>BEGAN</span>\n",
      "        </div>\n",
      "        <div id=\"top-right\">\n",
      "            <span>FUNNY</span>\n",
      "        </div>\n",
      "    </div>\n",
      "    <div id=\"bottom\">\n",
      "        <div id=\"bottom-left\">\n",
      "            <span>CHOSE</span>\n",
      "        </div>\n",
      "        <div id=\"bottom-right\">\n",
      "            <span>HARRY</span>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "```\n",
      "Note that I've used the `rgb()` function to specify the colors, but you can replace them with the corresponding hex codes if needed. Also, I've assumed that the font family \"Times New Roman\" is available on the system, if not, you can replace it with a fallback font family.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "test_index = 0\n",
    "text = filtered_data['test'][test_index]['svg']\n",
    "model = FastVisionModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(filtered_data['test'][test_index]['svg'])\n",
    "print(filtered_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(model, filtered_data['test'], steps+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4065cf71-3f41-4bb8-bf51-4faef98067ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6416387a763847db903b257f763c9472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in split:\n",
      " svg               0\n",
      "html              0\n",
      "text              0\n",
      "input_ids         0\n",
      "attention_mask    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = filtered_data['train'].select(range(1000)).map(tokenize_function, batched=True)\n",
    "\n",
    "df = tokenized_dataset.to_pandas()\n",
    "nan_counts = df.isna().sum()\n",
    "print(f\"NaN counts in split:\\n\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9316874-a10f-45d9-9ab9-28758b27e334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
