{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 fine tuning with \"chopped\" dataset\n",
    "\n",
    "2025-01-06 10:33\n",
    "\n",
    "Over a week of fine-tuning on the size-color-text data set. Unfortunately the training froze several times without an error message and had to be restarted. I might need to put the loss calculation on a web service. The loss did not improve over time and the output is not picking up on the colors and sizes. It's a little odd, and it might have something to do with the restarted traning although not sure. The loss is flat. The trained parameter size should not be an issue for a relatively simple data set like this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8567da-339d-42d8-a672-fd9474f75a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu bzip2 cpp cpp-11 dirmngr\n",
      "  dpkg-dev fakeroot g++ g++-11 gcc gcc-11 gcc-11-base gnupg gnupg-l10n\n",
      "  gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan6 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-11-dev libisl23 libitm1 libksba8\n",
      "  liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0 libstdc++-11-dev\n",
      "  libtsan0 libubsan1 lto-disabled-list make patch pinentry-curses xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-11-locales pinentry-gnome3 tor\n",
      "  debian-keyring g++-multilib g++-11-multilib gcc-11-doc gcc-multilib\n",
      "  manpages-dev autoconf automake libtool flex bison gdb gcc-doc\n",
      "  gcc-11-multilib parcimonie xloadimage scdaemon bzr libstdc++-11-doc make-doc\n",
      "  ed diffutils-doc pinentry-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-11 dirmngr dpkg-dev fakeroot g++ g++-11 gcc gcc-11 gcc-11-base gnupg\n",
      "  gnupg-l10n gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan6 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-11-dev libisl23 libitm1 libksba8\n",
      "  liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0 libstdc++-11-dev\n",
      "  libtsan0 libubsan1 lto-disabled-list make patch pinentry-curses xz-utils\n",
      "0 upgraded, 50 newly installed, 0 to remove and 29 not upgraded.\n",
      "Need to get 62.0 MB of archives.\n",
      "After this operation, 197 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 xz-utils amd64 5.2.5-2ubuntu1 [84.8 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.6 [222 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.6 [662 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf-nobfd0 amd64 2.38-4ubuntu2.6 [108 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.6 [103 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.6 [2326 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.6 [3200 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-11-base amd64 11.4.0-1ubuntu1~22.04 [20.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libisl23 amd64 0.24-2build1 [727 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmpfr6 amd64 4.1.0-3build3 [1425 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmpc3 amd64 1.2.1-2build1 [46.9 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-11 amd64 11.4.0-1ubuntu1~22.04 [10.0 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 cpp amd64 4:11.2.0-1ubuntu1 [27.7 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcc1-0 amd64 12.3.0-1ubuntu1~22.04 [48.3 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libitm1 amd64 12.3.0-1ubuntu1~22.04 [30.2 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan6 amd64 11.4.0-1ubuntu1~22.04 [2282 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 liblsan0 amd64 12.3.0-1ubuntu1~22.04 [1069 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan0 amd64 11.4.0-1ubuntu1~22.04 [2260 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libubsan1 amd64 12.3.0-1ubuntu1~22.04 [976 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-11-dev amd64 11.4.0-1ubuntu1~22.04 [2517 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-11 amd64 11.4.0-1ubuntu1~22.04 [20.1 MB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 gcc amd64 4:11.2.0-1ubuntu1 [5112 B]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libstdc++-11-dev amd64 11.4.0-1ubuntu1~22.04 [2101 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 g++-11 amd64 11.4.0-1ubuntu1~22.04 [11.4 MB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 g++ amd64 4:11.2.0-1ubuntu1 [1412 B]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 make amd64 4.3-4.1build1 [180 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdpkg-perl all 1.21.1ubuntu2.3 [237 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 bzip2 amd64 1.0.8-5build1 [34.8 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 patch amd64 2.7.6-7build2 [109 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 lto-disabled-list all 24 [12.5 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dpkg-dev all 1.21.1ubuntu2.3 [922 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 build-essential amd64 12.9ubuntu3 [4744 B]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libksba8 amd64 1.6.0-2ubuntu0.2 [119 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnpth0 amd64 1.6-3build2 [8664 B]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dirmngr amd64 2.2.27-3ubuntu2.1 [293 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg-l10n all 2.2.27-3ubuntu2.1 [54.4 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg-utils amd64 2.2.27-3ubuntu2.1 [308 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 pinentry-curses amd64 1.1.1-1build2 [34.4 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-agent amd64 2.2.27-3ubuntu2.1 [209 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-wks-client amd64 2.2.27-3ubuntu2.1 [62.7 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-wks-server amd64 2.2.27-3ubuntu2.1 [57.5 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpgsm amd64 2.2.27-3ubuntu2.1 [197 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg all 2.2.27-3ubuntu2.1 [315 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-diff-perl all 1.201-1 [41.8 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-diff-xs-perl amd64 0.04-6build3 [11.9 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-merge-perl all 0.08-3 [12.0 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfile-fcntllock-perl amd64 0.22-3build7 [33.9 kB]\n",
      "Fetched 62.0 MB in 2s (27.8 MB/s)                    \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "(Reading database ... 33501 files and directories currently installed.)\n",
      "Preparing to unpack .../00-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../01-xz-utils_5.2.5-2ubuntu1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.5-2ubuntu1) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../02-binutils-common_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../03-libbinutils_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../04-libctf-nobfd0_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libctf-nobfd0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../05-libctf0_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libctf0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../06-binutils-x86-64-linux-gnu_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../07-binutils_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package gcc-11-base:amd64.\n",
      "Preparing to unpack .../08-gcc-11-base_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking gcc-11-base:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libisl23:amd64.\n",
      "Preparing to unpack .../09-libisl23_0.24-2build1_amd64.deb ...\n",
      "Unpacking libisl23:amd64 (0.24-2build1) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../10-libmpfr6_4.1.0-3build3_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.1.0-3build3) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../11-libmpc3_1.2.1-2build1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.2.1-2build1) ...\n",
      "Selecting previously unselected package cpp-11.\n",
      "Preparing to unpack .../12-cpp-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking cpp-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../13-cpp_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking cpp (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../14-libcc1-0_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../15-libitm1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libasan6:amd64.\n",
      "Preparing to unpack .../16-libasan6_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libasan6:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../17-liblsan0_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../18-libtsan0_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libtsan0:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../19-libubsan1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libgcc-11-dev:amd64.\n",
      "Preparing to unpack .../20-libgcc-11-dev_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libgcc-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gcc-11.\n",
      "Preparing to unpack .../21-gcc-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking gcc-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../22-gcc_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking gcc (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package libstdc++-11-dev:amd64.\n",
      "Preparing to unpack .../23-libstdc++-11-dev_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libstdc++-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package g++-11.\n",
      "Preparing to unpack .../24-g++-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking g++-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../25-g++_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking g++ (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../26-make_4.3-4.1build1_amd64.deb ...\n",
      "Unpacking make (4.3-4.1build1) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../27-libdpkg-perl_1.21.1ubuntu2.3_all.deb ...\n",
      "Unpacking libdpkg-perl (1.21.1ubuntu2.3) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../28-bzip2_1.0.8-5build1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.8-5build1) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../29-patch_2.7.6-7build2_amd64.deb ...\n",
      "Unpacking patch (2.7.6-7build2) ...\n",
      "Selecting previously unselected package lto-disabled-list.\n",
      "Preparing to unpack .../30-lto-disabled-list_24_all.deb ...\n",
      "Unpacking lto-disabled-list (24) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../31-dpkg-dev_1.21.1ubuntu2.3_all.deb ...\n",
      "Unpacking dpkg-dev (1.21.1ubuntu2.3) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../32-build-essential_12.9ubuntu3_amd64.deb ...\n",
      "Unpacking build-essential (12.9ubuntu3) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../33-libksba8_1.6.0-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.6.0-2ubuntu0.2) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../34-libnpth0_1.6-3build2_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-3build2) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../35-dirmngr_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../36-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../37-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
      "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../38-gnupg-l10n_2.2.27-3ubuntu2.1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../39-gnupg-utils_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../40-pinentry-curses_1.1.1-1build2_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.1.1-1build2) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../41-gpg-agent_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../42-gpg-wks-client_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../43-gpg-wks-server_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../44-gpgsm_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../45-gnupg_2.2.27-3ubuntu2.1_all.deb ...\n",
      "Unpacking gnupg (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../46-libalgorithm-diff-perl_1.201-1_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.201-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl.\n",
      "Preparing to unpack .../47-libalgorithm-diff-xs-perl_0.04-6build3_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl (0.04-6build3) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../48-libalgorithm-merge-perl_0.08-3_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-3) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../49-libfile-fcntllock-perl_0.22-3build7_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-3build7) ...\n",
      "Setting up libksba8:amd64 (1.6.0-2ubuntu0.2) ...\n",
      "Setting up pinentry-curses (1.1.1-1build2) ...\n",
      "Setting up gcc-11-base:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up lto-disabled-list (24) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-3build7) ...\n",
      "Setting up libalgorithm-diff-perl (1.201-1) ...\n",
      "Setting up gpgsm (2.2.27-3ubuntu2.1) ...\n",
      "Setting up binutils-common:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libctf-nobfd0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libnpth0:amd64 (1.6-3build2) ...\n",
      "Setting up bzip2 (1.0.8-5build1) ...\n",
      "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
      "Setting up libasan6:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up fakeroot (1.28-1ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up dirmngr (2.2.27-3ubuntu2.1) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/dirmngr.socket → /usr/lib/systemd/user/dirmngr.socket.\n",
      "Setting up make (4.3-4.1build1) ...\n",
      "Setting up libmpfr6:amd64 (4.1.0-3build3) ...\n",
      "Setting up gnupg-l10n (2.2.27-3ubuntu2.1) ...\n",
      "Setting up xz-utils (5.2.5-2ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libmpc3:amd64 (1.2.1-2build1) ...\n",
      "Setting up patch (2.7.6-7build2) ...\n",
      "Setting up libdpkg-perl (1.21.1ubuntu2.3) ...\n",
      "Setting up libubsan1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libbinutils:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libisl23:amd64 (0.24-2build1) ...\n",
      "Setting up libalgorithm-diff-xs-perl (0.04-6build3) ...\n",
      "Setting up libcc1-0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
      "Setting up liblsan0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libitm1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-3) ...\n",
      "Setting up gnupg-utils (2.2.27-3ubuntu2.1) ...\n",
      "Setting up libtsan0:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up libctf0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up cpp-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gpg-agent (2.2.27-3ubuntu2.1) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-browser.socket → /usr/lib/systemd/user/gpg-agent-browser.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-extra.socket → /usr/lib/systemd/user/gpg-agent-extra.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-ssh.socket → /usr/lib/systemd/user/gpg-agent-ssh.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent.socket → /usr/lib/systemd/user/gpg-agent.socket.\n",
      "Setting up gpg-wks-client (2.2.27-3ubuntu2.1) ...\n",
      "Setting up gpg-wks-server (2.2.27-3ubuntu2.1) ...\n",
      "Setting up libgcc-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up cpp (4:11.2.0-1ubuntu1) ...\n",
      "Setting up gnupg (2.2.27-3ubuntu2.1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.6) ...\n",
      "Setting up binutils (2.38-4ubuntu2.6) ...\n",
      "Setting up dpkg-dev (1.21.1ubuntu2.3) ...\n",
      "Setting up libstdc++-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gcc-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up g++-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gcc (4:11.2.0-1ubuntu1) ...\n",
      "Setting up g++ (4:11.2.0-1ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/c++.1.gz because associated file /usr/share/man/man1/g++.1.gz (of link group c++) doesn't exist\n",
      "Setting up build-essential (12.9ubuntu3) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Using cached unsloth-2024.12.11-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting unsloth_zoo>=2024.12.5 (from unsloth)\n",
      "  Using cached unsloth_zoo-2024.12.6-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (2.4.0)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.29-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (3.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from unsloth) (24.1)\n",
      "Collecting tyro (from unsloth)\n",
      "  Using cached tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets>=2.16.0 (from unsloth)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from unsloth) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from unsloth) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unsloth) (2.2.1)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Using cached accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Using cached trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Using cached peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting huggingface_hub (from unsloth)\n",
      "  Using cached huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Using cached hf_transfer-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.1->unsloth) (6.0.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Using cached safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth)\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.16.0->unsloth)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
      "Collecting aiohttp (from datasets>=2.16.0->unsloth)\n",
      "  Using cached aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->unsloth) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,>=4.46.1->unsloth)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting rich (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2024.12.5->unsloth)\n",
      "  Using cached cut_cross_entropy-24.12.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.5->unsloth) (10.4.0)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2.4.0->unsloth)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Using cached typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.7.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.16.0->unsloth)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
      "Downloading unsloth-2024.12.11-py3-none-any.whl (175 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m175.2/175.2 kB\u001B[0m \u001B[31m14.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m336.4/336.4 kB\u001B[0m \u001B[31m88.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m142.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m450.5/450.5 kB\u001B[0m \u001B[31m144.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m374.8/374.8 kB\u001B[0m \u001B[31m130.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m162.1/162.1 kB\u001B[0m \u001B[31m88.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m181.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.1/10.1 MB\u001B[0m \u001B[31m230.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m293.4/293.4 kB\u001B[0m \u001B[31m109.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading unsloth_zoo-2024.12.6-py3-none-any.whl (70 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m70.9/70.9 kB\u001B[0m \u001B[31m44.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xformers-0.0.29-cp311-cp311-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.3/15.3 MB\u001B[0m \u001B[31m32.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m906.5/906.5 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.5/209.5 MB\u001B[0m \u001B[31m36.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m23.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m208.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m153.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m170.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m36.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m22.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m48.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m38.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m188.7/188.7 MB\u001B[0m \u001B[31m42.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m168.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m44.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m214.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.1/69.1 MB\u001B[0m \u001B[31m90.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading hf_transfer-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m174.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tyro-0.9.5-py3-none-any.whl (112 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m112.5/112.5 kB\u001B[0m \u001B[31m58.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m65.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m179.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m79.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.1/40.1 MB\u001B[0m \u001B[31m130.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m242.4/242.4 kB\u001B[0m \u001B[31m94.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m435.0/435.0 kB\u001B[0m \u001B[31m140.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m206.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Downloading cut_cross_entropy-24.12.3-py3-none-any.whl (22 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m201.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.8/194.8 kB\u001B[0m \u001B[31m90.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m274.9/274.9 kB\u001B[0m \u001B[31m101.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m87.5/87.5 kB\u001B[0m \u001B[31m47.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.0/129.0 kB\u001B[0m \u001B[31m66.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m231.1/231.1 kB\u001B[0m \u001B[31m101.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m346.6/346.6 kB\u001B[0m \u001B[31m124.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m344.1/344.1 kB\u001B[0m \u001B[31m122.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: sentencepiece, xxhash, tzdata, typeguard, triton, sympy, shtab, safetensors, pyarrow, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, mdurl, hf_transfer, frozenlist, docstring-parser, dill, aiohappyeyeballs, yarl, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, huggingface_hub, aiosignal, tokenizers, rich, nvidia-cusolver-cu12, aiohttp, tyro, transformers, torch, xformers, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.2\n",
      "    Uninstalling protobuf-5.29.2:\n",
      "      Successfully uninstalled protobuf-5.29.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "Successfully installed accelerate-1.2.1 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 bitsandbytes-0.45.0 cut_cross_entropy-24.12.3 datasets-3.2.0 dill-0.3.8 docstring-parser-0.16 frozenlist-1.5.0 hf_transfer-0.1.8 huggingface_hub-0.27.0 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 peft-0.14.0 propcache-0.2.1 protobuf-3.20.3 pyarrow-18.1.0 rich-13.9.4 safetensors-0.4.5 sentencepiece-0.2.0 shtab-1.7.1 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.1 triton-3.1.0 trl-0.13.0 typeguard-4.4.1 tyro-0.9.5 tzdata-2024.2 unsloth-2024.12.11 unsloth_zoo-2024.12.6 xformers-0.0.29 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mFound existing installation: unsloth 2024.12.11\n",
      "Uninstalling unsloth-2024.12.11:\n",
      "  Successfully uninstalled unsloth-2024.12.11\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-6t9hucsj/unsloth_96792cd27eaa4f439c5e1a454740df65\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-6t9hucsj/unsloth_96792cd27eaa4f439c5e1a454740df65\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit bc5f726a3cba3dbacda604a288dbc352c0baa737\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: unsloth_zoo>=2024.12.6 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
      "Requirement already satisfied: tyro in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.5)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.47.1)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.27.0)\n",
      "Requirement already satisfied: hf_transfer in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: bitsandbytes>=0.43.3 in /opt/conda/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.12.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2024.12.6->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.4.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.15.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.3)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for unsloth: filename=unsloth-2024.12.11-py3-none-any.whl size=174742 sha256=0c0285e4d19d8fdd1e4e8ef66049faa431d2ae57dcbc99ebced056bd6e783c1d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y6k_6hh5/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.12.11\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.11/site-packages (2.4.3)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (3.0.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (2.2.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu) (5.3.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: pytest-playwright in /opt/conda/lib/python3.11/site-packages (0.6.2)\n",
      "Requirement already satisfied: playwright>=1.18 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (1.49.1)\n",
      "Requirement already satisfied: pytest<9.0.0,>=6.2.4 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.3.3)\n",
      "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (2.1.0)\n",
      "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from pytest-playwright) (8.0.4)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (3.1.1)\n",
      "Requirement already satisfied: pyee==12.0.0 in /opt/conda/lib/python3.11/site-packages (from playwright>=1.18->pytest-playwright) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from pyee==12.0.0->playwright>=1.18->pytest-playwright) (4.11.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.11/site-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.9 in /opt/conda/lib/python3.11/site-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.32.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.11/site-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2024.7.4)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (10.4.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: lpips in /opt/conda/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /opt/conda/lib/python3.11/site-packages (from lpips) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (1.14.1)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /opt/conda/lib/python3.11/site-packages (from lpips) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.2.1->lpips) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=0.4.0->lpips) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mInstalling dependencies...\n",
      "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
      "fonts-liberation is already the newest version (1:1.07.4-11).\n",
      "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
      "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
      "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
      "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
      "libcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libdbus-glib-1-2 is already the newest version (0.112-2build1).\n",
      "libegl1 is already the newest version (1.4.0-1).\n",
      "libenchant-2-2 is already the newest version (2.3.2-1ubuntu2).\n",
      "libepoxy0 is already the newest version (1.5.10-1).\n",
      "libevdev2 is already the newest version (1.12.1+dfsg-1).\n",
      "libevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\n",
      "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
      "libgles2 is already the newest version (1.4.0-1).\n",
      "libglx0 is already the newest version (1.4.0-1).\n",
      "libgudev-1.0-0 is already the newest version (1:237-2build1).\n",
      "libhyphen0 is already the newest version (2.8.8-7build2).\n",
      "libicu70 is already the newest version (70.1-2).\n",
      "libjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\n",
      "liblcms2-2 is already the newest version (2.12~rc1-2build2).\n",
      "libmanette-0.2-0 is already the newest version (0.2.6-3build1).\n",
      "libopengl0 is already the newest version (1.4.0-1).\n",
      "libopus0 is already the newest version (1.3.1-0.1build2).\n",
      "libpng16-16 is already the newest version (1.6.37-3build5).\n",
      "libproxy1v5 is already the newest version (0.4.17-2).\n",
      "libsecret-1-0 is already the newest version (0.20.5-2).\n",
      "libwoff1 is already the newest version (1.0.2-1build4).\n",
      "libxcb-shm0 is already the newest version (1.14-3ubuntu3).\n",
      "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
      "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
      "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
      "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
      "libxext6 is already the newest version (2:1.3.4-1build1).\n",
      "libxfixes3 is already the newest version (1:6.0.0-1).\n",
      "libxi6 is already the newest version (2:1.8-1build1).\n",
      "libxkbcommon0 is already the newest version (1.4.0-1).\n",
      "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
      "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
      "libxtst6 is already the newest version (2:1.2.3-1build4).\n",
      "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
      "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
      "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
      "fonts-unifont is already the newest version (1:14.0.01-1).\n",
      "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
      "libavif13 is already the newest version (0.9.3-3).\n",
      "libffi7 is already the newest version (3.3-5ubuntu1).\n",
      "libx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\n",
      "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
      "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-plugins-base is already the newest version (1.20.1-1ubuntu0.4).\n",
      "gstreamer1.0-plugins-good is already the newest version (1.20.3-0ubuntu1.3).\n",
      "libatomic1 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
      "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
      "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
      "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
      "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
      "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
      "libgdk-pixbuf-2.0-0 is already the newest version (2.42.8+dfsg-1ubuntu0.3).\n",
      "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
      "libglib2.0-0 set to manually installed.\n",
      "libgstreamer-gl1.0-0 is already the newest version (1.20.1-1ubuntu0.4).\n",
      "libgstreamer-plugins-base1.0-0 is already the newest version (1.20.1-1ubuntu0.4).\n",
      "libgstreamer1.0-0 is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libgstreamer1.0-0 set to manually installed.\n",
      "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\n",
      "libharfbuzz-icu0 is already the newest version (2.7.4-1ubuntu3.1).\n",
      "libharfbuzz0b is already the newest version (2.7.4-1ubuntu3.1).\n",
      "libnotify4 is already the newest version (0.7.9-3ubuntu5.22.04.1).\n",
      "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
      "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
      "libopenjp2-7 is already the newest version (2.4.0-6ubuntu0.2).\n",
      "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\n",
      "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libxml2 is already the newest version (2.9.13+dfsg-1ubuntu0.4).\n",
      "libxslt1.1 is already the newest version (1.1.34-4ubuntu0.22.04.1).\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "gstreamer1.0-libav is already the newest version (1.20.3-0ubuntu1).\n",
      "gstreamer1.0-plugins-bad is already the newest version (1.20.3-0ubuntu1.1).\n",
      "libsoup-3.0-0 is already the newest version (3.0.7-0ubuntu1).\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.2.1)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.2.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (69.5.1)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "!pip install sacrebleu\n",
    "!pip install pytest-playwright\n",
    "!playwright install\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install torchvision\n",
    "!pip install lpips\n",
    "\n",
    "!playwright install-deps  \n",
    "\n",
    "!pip install -U numpy\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 131_072\n",
    "\n",
    "def load_model():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=\"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    \n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "        use_rslora=True,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state = 32,\n",
    "        loftq_config = None,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167425bb45a12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, training_data, max_steps):\n",
    "    training_arguments = TrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=64,\n",
    "        num_train_epochs=40,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        # max_steps=max_steps,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=10,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    if max_steps is not None:\n",
    "        training_arguments.max_steps = max_steps\n",
    "    \n",
    "    return SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=training_data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=10,\n",
    "        packing=True,\n",
    "        args=training_arguments,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label)\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    results = {\n",
    "        \"similarity\": float(np.mean(similarity_scores)),\n",
    "        \"perceptual_loss\": float(np.mean(perceptual_losses)),\n",
    "    }\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', results['similarity'], steps)\n",
    "    writer.add_scalar('perceptual_loss', results['perceptual_loss'], steps)\n",
    "    \n",
    "    print(\"Similarity:\", results['similarity'])\n",
    "    print(\"Perceptual loss:\", results['perceptual_loss'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9436b4-22de-4180-a7d6-9aad00934c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c8b3c6163163d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-12build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
      "--2024-12-28 14:01:38--  https://www.dropbox.com/scl/fi/689uan4tngw5z1b38hlgt/data-rb-size-color-text.zip?rlkey=tpl5lin2hh2vyn5k3c4dcdanw&dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.13.18, 2620:100:6057:18::a27d:d12\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.13.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com/cd/0/inline/ChFJuhnuQI87BhArxW-kT2t4STu2b0DY6PWVHI0ArIEn_Jw-9gE9prU7XmdWHXW8exEbGFCIkjdeWLvuH7Op_llRJyJBEkJ_CN5I6FoWTb5f4SZRj4vqxzUq8NOqD-y6FR0/file# [following]\n",
      "--2024-12-28 14:01:39--  https://uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com/cd/0/inline/ChFJuhnuQI87BhArxW-kT2t4STu2b0DY6PWVHI0ArIEn_Jw-9gE9prU7XmdWHXW8exEbGFCIkjdeWLvuH7Op_llRJyJBEkJ_CN5I6FoWTb5f4SZRj4vqxzUq8NOqD-y6FR0/file\n",
      "Resolving uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com (uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com)... 162.125.13.15, 2620:100:6057:15::a27d:d0f\n",
      "Connecting to uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com (uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com)|162.125.13.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/ChH7T71vRO1WSQe0u-0fFOHHwdqOHXtTezxx1bxBZVVFqqQYUOqV_xV3qvFW81S4kynbdFVOSt7BhMdXQe7XPJ_LVBtsXV_m-tvYKPNzc7--9_AHa14sEd7NWqwUySEeg3OnnAvJci3oLAS6vmo0vjOxrUFUHs_FviTsWqK_kiJy0tOaXlRpm49ApnQSs6ZUqh0dLil7gvIei29X3YaROSFNiIWOdtMfy3hIqdanj7ZZu0awl44aYJkY2YTZfLCHkyC3V7TumV29TteDVkJ0o_CMJjqFE0jW6IbQA50tXKLZEwENHAGAQnbytaIy08NdwX0J7JR4YSPjOj5ycAJEljBU5yWpvU6MinlciwYmdopPSw/file [following]\n",
      "--2024-12-28 14:01:40--  https://uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com/cd/0/inline2/ChH7T71vRO1WSQe0u-0fFOHHwdqOHXtTezxx1bxBZVVFqqQYUOqV_xV3qvFW81S4kynbdFVOSt7BhMdXQe7XPJ_LVBtsXV_m-tvYKPNzc7--9_AHa14sEd7NWqwUySEeg3OnnAvJci3oLAS6vmo0vjOxrUFUHs_FviTsWqK_kiJy0tOaXlRpm49ApnQSs6ZUqh0dLil7gvIei29X3YaROSFNiIWOdtMfy3hIqdanj7ZZu0awl44aYJkY2YTZfLCHkyC3V7TumV29TteDVkJ0o_CMJjqFE0jW6IbQA50tXKLZEwENHAGAQnbytaIy08NdwX0J7JR4YSPjOj5ycAJEljBU5yWpvU6MinlciwYmdopPSw/file\n",
      "Reusing existing connection to uc508029b6da911debf9a83ba374.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31833746 (30M) [application/zip]\n",
      "Saving to: ‘model.zip’\n",
      "\n",
      "model.zip           100%[===================>]  30.36M  12.2MB/s    in 2.5s    \n",
      "\n",
      "2024-12-28 14:01:43 (12.2 MB/s) - ‘model.zip’ saved [31833746/31833746]\n",
      "\n",
      "Archive:  model.zip\n",
      "  inflating: data-rb-size-color-text/state.json  \n",
      "  inflating: data-rb-size-color-text/dataset_info.json  \n",
      "  inflating: data-rb-size-color-text/data-00000-of-00002.arrow  \n",
      "  inflating: data-rb-size-color-text/data-00001-of-00002.arrow  \n"
     ]
    }
   ],
   "source": [
    "!apt install zip -y\n",
    "!rm -rf data-rb-size-color-text\n",
    "!mkdir -p data-rb-size-color-text\n",
    "!wget \"https://www.dropbox.com/scl/fi/689uan4tngw5z1b38hlgt/data-rb-size-color-text.zip?rlkey=tpl5lin2hh2vyn5k3c4dcdanw&dl=0\" -O model.zip\n",
    "!unzip model.zip -d data-rb-size-color-text\n",
    "\n",
    "!rm -rf data-rb-validate\n",
    "!mkdir -p data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f3d9ae5b9b9f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html'],\n",
       "        num_rows: 99849\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('data-rb-size-color-text')\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=4/len(dataset))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bf3a2cdcc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.11: Fast Llama patching. Transformers: 4.47.1.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.003 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.11 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model()\n",
    "\n",
    "data_prompt = \"\"\"Your job is to take an SVG file of a web design and convert it into a pixel-perfect HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"svg\"]\n",
    "    outputs      = examples[\"html\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57abcb9-04a6-4ad6-91af-7fd09e7118ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f97354530d54918946ce31a0a8fbf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ec38b5458d4c5cad99032b5bc0a96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "335b25f6-18b9-4ac9-bad7-2d6ccfe2355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 99849\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8289ee3c-34eb-4ca3-b69b-2e7a2828a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d1e4cee1ca4445860998ed00e6d83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca533cb69ec4c329ed03b2481056f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3fa3efa2c84f48afd2825077e7481d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/99849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01955f9edb64acf8c2b13ddaf840dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 99849\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def get_token_lengths(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=False,  # Don't truncate yet\n",
    "        padding=False,     # Don't pad yet\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = training_data.map(get_token_lengths, batched=True)\n",
    "\n",
    "def filter_function(example):\n",
    "    return example['length'] <= max_seq_length\n",
    "\n",
    "filtered_data = tokenized_data.filter(filter_function)\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90aeb44b-e661-4d7b-8a56-995d7e115332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978c48317d8f453f8cc1a37682fddf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/99849 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab687d38bae48ea8eab3977c0ee5255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_data = filtered_data.remove_columns([\"input_ids\", \"attention_mask\", \"length\"])\n",
    "filtered_data.save_to_disk('data-rb-size-color-text-filtered-' + str(max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f049b9-5e8c-4b01-aaa1-bf0b9024d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 99849\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "filtered_data = load_from_disk('data-rb-size-color-text-filtered-' + str(max_seq_length))\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae39d89303cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 18\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 159\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='161' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/159 00:00, Epoch 17/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/201 [1:00:58<203:14:38, 3658.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 18\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 160\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:00, Epoch 17/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/201 [2:01:49<201:59:13, 3654.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 18\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 161\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/161 : < :, Epoch 17/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/201 [2:04:55<113:52:04, 2070.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 18\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 162\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 : < :, Epoch 17/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/201 [2:08:02<72:37:15, 1327.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 163\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='163' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163/163 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/201 [3:08:49<117:48:12, 2163.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 164\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/201 [4:09:44<144:39:20, 2670.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 165\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [165/165 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/201 [5:10:32<161:08:08, 2990.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 166\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='166' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [166/166 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/201 [6:11:31<171:43:32, 3203.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 167\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [167/167 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.285700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/201 [7:12:17<178:13:01, 3341.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 168\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 10/201 [8:13:17<182:30:28, 3439.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 169\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='169' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [169/169 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 11/201 [9:14:06<184:55:04, 3503.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 170\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.286100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/201 [10:15:00<186:21:10, 3549.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 19\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 171\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 00:00, Epoch 18/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/201 [11:15:52<186:59:08, 3580.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 20\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 172\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/172 00:00, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/201 [12:16:50<187:12:32, 3604.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 20\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 173\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='173' max='173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [173/173 00:00, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 15/201 [13:17:42<186:56:50, 3618.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n",
      "Steps: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,219 | Num Epochs = 20\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 64\n",
      "\\        /    Total batch size = 128 | Total steps = 174\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n",
      " 12%|█▏        | 25/201 [24:03:32<169:22:35, 3464.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m trainer \u001B[38;5;241m=\u001B[39m create_trainer(model, tokenizer, filtered_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m], steps)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resume:\n\u001B[0;32m---> 12\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtrain(resume_from_checkpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m<string>:157\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m<string>:382\u001B[0m, in \u001B[0;36m_fast_inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n",
      "File \u001B[0;32m<string>:31\u001B[0m, in \u001B[0;36m_unsloth_training_step\u001B[0;34m(self, model, inputs, num_items_in_batch)\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/_utils.py:1028\u001B[0m, in \u001B[0;36m_unsloth_pre_compute_loss\u001B[0;34m(self, model, inputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1026\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m-> 1028\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_old_compute_loss(model, inputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:3708\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001B[0m\n\u001B[1;32m   3706\u001B[0m         loss_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_items_in_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_items_in_batch\n\u001B[1;32m   3707\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_kwargs}\n\u001B[0;32m-> 3708\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[1;32m   3709\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3710\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:823\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:811\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 811\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:823\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:811\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 811\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "    \u001B[0;31m[... skipping similar frames: ConvertOutputsToFp32.__call__ at line 811 (23 times), autocast_decorator.<locals>.decorate_autocast at line 44 (23 times), convert_outputs_to_fp32.<locals>.forward at line 823 (23 times)]\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:823\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/operations.py:811\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 811\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 44\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/_compile.py:32\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     29\u001B[0m     disable_fn \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mdisable(fn, recursive)\n\u001B[1;32m     30\u001B[0m     fn\u001B[38;5;241m.\u001B[39m__dynamo_disable \u001B[38;5;241m=\u001B[39m disable_fn\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m disable_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632\u001B[0m, in \u001B[0;36mDisableContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    630\u001B[0m prior \u001B[38;5;241m=\u001B[39m _maybe_set_eval_frame(callback)\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    634\u001B[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:1118\u001B[0m, in \u001B[0;36mPeftModelForCausalLM_fast_forward\u001B[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, **kwargs)\u001B[0m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39m_disable_dynamo\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mPeftModelForCausalLM_fast_forward\u001B[39m(\n\u001B[1;32m   1105\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1116\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1117\u001B[0m ):\n\u001B[0;32m-> 1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model(\n\u001B[1;32m   1119\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1120\u001B[0m         causal_mask\u001B[38;5;241m=\u001B[39mcausal_mask,\n\u001B[1;32m   1121\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1122\u001B[0m         inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m   1123\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m   1124\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1125\u001B[0m         output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m   1126\u001B[0m         return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1127\u001B[0m         num_logits_to_keep\u001B[38;5;241m=\u001B[39mnum_logits_to_keep,\n\u001B[1;32m   1128\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1129\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:197\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:980\u001B[0m, in \u001B[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001B[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001B[0m\n\u001B[1;32m    978\u001B[0m     \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[1;32m    979\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39m_has_no_labels \u001B[38;5;241m=\u001B[39m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 980\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[1;32m    981\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    982\u001B[0m         causal_mask\u001B[38;5;241m=\u001B[39mcausal_mask,\n\u001B[1;32m    983\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    984\u001B[0m         position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m    985\u001B[0m         past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m    986\u001B[0m         inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m    987\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m    988\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    989\u001B[0m         output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    990\u001B[0m         return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    991\u001B[0m     )\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    993\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:811\u001B[0m, in \u001B[0;36mLlamaModel_fast_forward\u001B[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m offloaded_gradient_checkpointing:\n\u001B[0;32m--> 811\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m Unsloth_Offloaded_Gradient_Checkpointer\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m    812\u001B[0m         decoder_layer,\n\u001B[1;32m    813\u001B[0m         hidden_states,\n\u001B[1;32m    814\u001B[0m         mask,\n\u001B[1;32m    815\u001B[0m         attention_mask,\n\u001B[1;32m    816\u001B[0m         position_ids,\n\u001B[1;32m    817\u001B[0m         past_key_values,\n\u001B[1;32m    818\u001B[0m         output_attentions,\n\u001B[1;32m    819\u001B[0m         use_cache,\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    821\u001B[0m         position_embeddings,\n\u001B[1;32m    822\u001B[0m     )[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m gradient_checkpointing:\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_custom_forward\u001B[39m(module):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py:575\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    574\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    583\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/amp/autocast_mode.py:465\u001B[0m, in \u001B[0;36mcustom_fwd.<locals>.decorate_fwd\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cast_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fwd_used_autocast \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled(device_type)\n\u001B[0;32m--> 465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fwd(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    467\u001B[0m     autocast_context \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled(device_type)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py:156\u001B[0m, in \u001B[0;36mUnsloth_Offloaded_Gradient_Checkpointer.forward\u001B[0;34m(ctx, forward_function, hidden_states, *args)\u001B[0m\n\u001B[1;32m    154\u001B[0m saved_hidden_states \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, non_blocking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 156\u001B[0m     output \u001B[38;5;241m=\u001B[39m forward_function(hidden_states, \u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    157\u001B[0m ctx\u001B[38;5;241m.\u001B[39msave_for_backward(saved_hidden_states)\n\u001B[1;32m    158\u001B[0m ctx\u001B[38;5;241m.\u001B[39mforward_function \u001B[38;5;241m=\u001B[39m forward_function\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:502\u001B[0m, in \u001B[0;36mLlamaDecoderLayer_fast_forward\u001B[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001B[0m\n\u001B[1;32m    500\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    501\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m fast_rms_layernorm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm, hidden_states)\n\u001B[0;32m--> 502\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn(\n\u001B[1;32m    503\u001B[0m     hidden_states       \u001B[38;5;241m=\u001B[39m hidden_states,\n\u001B[1;32m    504\u001B[0m     causal_mask         \u001B[38;5;241m=\u001B[39m causal_mask,\n\u001B[1;32m    505\u001B[0m     attention_mask      \u001B[38;5;241m=\u001B[39m attention_mask,\n\u001B[1;32m    506\u001B[0m     position_ids        \u001B[38;5;241m=\u001B[39m position_ids,\n\u001B[1;32m    507\u001B[0m     past_key_value      \u001B[38;5;241m=\u001B[39m past_key_value,\n\u001B[1;32m    508\u001B[0m     output_attentions   \u001B[38;5;241m=\u001B[39m output_attentions,\n\u001B[1;32m    509\u001B[0m     use_cache           \u001B[38;5;241m=\u001B[39m use_cache,\n\u001B[1;32m    510\u001B[0m     padding_mask        \u001B[38;5;241m=\u001B[39m padding_mask,\n\u001B[1;32m    511\u001B[0m     position_embeddings \u001B[38;5;241m=\u001B[39m position_embeddings,\n\u001B[1;32m    512\u001B[0m )\n\u001B[1;32m    513\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    515\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/models/llama.py:445\u001B[0m, in \u001B[0;36mLlamaAttention_fast_forward\u001B[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    444\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mreshape(bsz, q_len, n_heads\u001B[38;5;241m*\u001B[39mhead_dim)\n\u001B[0;32m--> 445\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_o(\u001B[38;5;28mself\u001B[39m, attn_output)\n\u001B[1;32m    446\u001B[0m attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m attn_output, attn_weights, past_key_value\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/kernels/fast_lora.py:410\u001B[0m, in \u001B[0;36mapply_lora_o\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_lora_o\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    409\u001B[0m     OW, OW_quant, OA, OB, OS \u001B[38;5;241m=\u001B[39m get_lora_parameters(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mo_proj)\n\u001B[0;32m--> 410\u001B[0m     O \u001B[38;5;241m=\u001B[39m LoRA_W\u001B[38;5;241m.\u001B[39mapply(X, OW, OW_quant, OA, OB, OS)\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m O\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py:575\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    574\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    583\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/torch/amp/autocast_mode.py:465\u001B[0m, in \u001B[0;36mcustom_fwd.<locals>.decorate_fwd\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cast_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fwd_used_autocast \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled(device_type)\n\u001B[0;32m--> 465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fwd(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    467\u001B[0m     autocast_context \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled(device_type)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/kernels/fast_lora.py:369\u001B[0m, in \u001B[0;36mLoRA_W.forward\u001B[0;34m(ctx, X, W, W_quant, A, B, S)\u001B[0m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;129m@torch_amp_custom_fwd\u001B[39m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(ctx, X : torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    367\u001B[0m             W, W_quant, A, B, S):\n\u001B[1;32m    368\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m--> 369\u001B[0m     XW \u001B[38;5;241m=\u001B[39m matmul_lora(X, W, W_quant, A, B, S)\n\u001B[1;32m    370\u001B[0m     ctx\u001B[38;5;241m.\u001B[39mcustom_saved_tensors \u001B[38;5;241m=\u001B[39m (W, W_quant, S,)\n\u001B[1;32m    371\u001B[0m     ctx\u001B[38;5;241m.\u001B[39msave_for_backward(A, B, X)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/unsloth/kernels/utils.py:421\u001B[0m, in \u001B[0;36mmatmul_lora\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    418\u001B[0m     out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (X \u001B[38;5;241m@\u001B[39m A\u001B[38;5;241m.\u001B[39mto(dtype)) \u001B[38;5;241m@\u001B[39m (s \u001B[38;5;241m*\u001B[39m B\u001B[38;5;241m.\u001B[39mto(dtype))\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 421\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39mview(batch, seq_len, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m reshape \u001B[38;5;28;01melse\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# resume = False\n",
    "resume = True\n",
    "for steps in tqdm(range(159, 360, 1)):\n",
    "    print(f\"Steps: {steps}\")\n",
    "\n",
    "    if steps > 0:\n",
    "        trainer = create_trainer(model, tokenizer, filtered_data['train'], steps)\n",
    "        if resume:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "            resume = True\n",
    "        \n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "    results = test_prediction(model, filtered_data['test'], steps)\n",
    "\n",
    "    if results is not None and results['perceptual_loss'] == 0.0:\n",
    "        break\n",
    "\n",
    "    model = FastLanguageModel.for_training(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><div id=\"top\"><div id=\"top-left\">NIGHT</div><div id=\"top-right\">OCCUR</div></div><div id=\"bottom\"><div id=\"bottom-left\">QUEEN</div><div id=\"bottom-right\">QUEEN</div></div></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            margin: 0;\n",
      "            display: flex;\n",
      "            flex-direction: column;\n",
      "            min-height: 100vh;\n",
      "            font-weight: bold;\n",
      "        }\n",
      "\n",
      "        #top {\n",
      "            background-color: #7dc826;\n",
      "            flex-basis: 52vh;\n",
      "            flex-grow: 0;\n",
      "            flex-shrink: 0;\n",
      "            color: #5ade23;\n",
      "            font-size: 27px;\n",
      "        }\n",
      "\n",
      "        #bottom {\n",
      "            background-color: #0ce6ce;\n",
      "            flex: 1 1 auto;\n",
      "            color: #69150d;\n",
      "            font-size: 18pt;\n",
      "        }\n",
      "\n",
      "        #top, #bottom {\n",
      "            display: flex;\n",
      "        }\n",
      "\n",
      "        #top-left {\n",
      "            flex-basis: 68vw;\n",
      "            background: #64190b;\n",
      "            color: #7018f0;\n",
      "            font-size: 3em;\n",
      "        }\n",
      "\n",
      "        #bottom-left {\n",
      "            flex-basis: 163px;\n",
      "            background: #c399e8;\n",
      "            color: #a80e0d;\n",
      "            font-size: 55%;\n",
      "        }\n",
      "\n",
      "\n",
      "</style>\n",
      "Answer of the question is: \n",
      "```\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>HTML and CSS</title>\n",
      "    <style>\n",
      "        html {\n",
      "            background-color: #F0F0F0;\n",
      "        }\n",
      "        body {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #head1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #body1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top-left {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top-right {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom-left {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom-right {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #style1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"top\"></div>\n",
      "    <div id=\"bottom\"></div>\n",
      "    <div id=\"head1\"></div>\n",
      "    <div id=\"body1\"></div>\n",
      "    <div id=\"style1\"></div>\n",
      "</body>\n",
      "</html>\n",
      "```\n",
      "### Output:\n",
      "```\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>HTML and CSS</title>\n",
      "    <style>\n",
      "        html {\n",
      "            background-color: #F0F0F0;\n",
      "        }\n",
      "        body {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #head1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #body1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top-left {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #top-right {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom-left {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #bottom-right {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "        #style1 {\n",
      "            background-color: #F0F0F0;\n",
      "            color: #F0F0F0;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"top\"></div>\n",
      "    <div id=\"bottom\"></div>\n",
      "    <div id=\"head1\"></div>\n",
      "    <div id=\"body1\"></div>\n",
      "    <div id=\"style1\"></div>\n",
      "</body>\n",
      "</html>\n",
      "```<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "test_index = 0\n",
    "text = filtered_data['test'][test_index]['svg']\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(filtered_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n",
      "Similarity: 0.6557506948709488\n",
      "Perceptual loss: 0.6466260254383087\n"
     ]
    }
   ],
   "source": [
    "test_prediction(model, filtered_data['test'], steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065cf71-3f41-4bb8-bf51-4faef98067ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
