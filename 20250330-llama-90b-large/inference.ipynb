{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 90B fine tuning with large data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer, AutoTokenizer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, FastVisionModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "VIEWPORT_SIZES = {\n",
    "    'DESKTOP': {'width': 1440, 'height': 900},\n",
    "    'TABLET': {'width': 834, 'height': 1210},\n",
    "    'MOBILE': {'width': 393, 'height': 852},\n",
    "}\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label, \n",
    "                                    VIEWPORT_SIZES['MOBILE']['width'], VIEWPORT_SIZES['MOBILE']['height'])\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    results = {\n",
    "        \"similarity\": float(np.mean(similarity_scores)),\n",
    "        \"perceptual_loss\": float(np.mean(perceptual_losses)),\n",
    "    }\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', results['similarity'], steps)\n",
    "    writer.add_scalar('perceptual_loss', results['perceptual_loss'], steps)\n",
    "    \n",
    "    print(\"Similarity:\", results['similarity'])\n",
    "    print(\"Perceptual loss:\", results['perceptual_loss'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    return compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f049b9-5e8c-4b01-aaa1-bf0b9024d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66638a1ccc2410882a0f8e7174cdd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100502\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 23\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "filtered_data = load_from_disk('data-rb-large-filtered-' + str(max_seq_length))\n",
    "\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2418c1d1-dd0b-4900-9a74-d10afa632f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some reshuffling because:\n",
    "# 1. The validation data set is arguably too simple for the 90B model and it does a pretty good job even before fine-tuning\n",
    "# 2. The test data set is too small because of the filtering\n",
    "\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "new_valid_data = concatenate_datasets([\n",
    "    filtered_data['valid'],\n",
    "    filtered_data['train'].select(range(25))\n",
    "])\n",
    "\n",
    "new_test_data = concatenate_datasets([\n",
    "    filtered_data['test'],\n",
    "    filtered_data['train'].select(range(25, 52))\n",
    "])\n",
    "\n",
    "new_train_data = filtered_data['train'].select(range(25, len(filtered_data['train'])))\n",
    "\n",
    "filtered_data = DatasetDict({\n",
    "    'train': new_train_data,\n",
    "    'valid': new_valid_data,\n",
    "    'test': new_test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a175e842-6188-427b-8ad4-5bbf85783f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100477\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 29\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904702ca-46fa-4a1c-94cc-b1cffddc6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prompt = \"\"\"Your job is to take an SVG file of a web design and convert it into a pixel-perfect HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.3: Fast Mllama vision patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.111 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efad7a3caed54c989add8361dac4b262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"center1 hr1 center2 style1\"><g data-tag=\"center\" id=\"center1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"h11\"><g data-tag=\"h1\" id=\"h11\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"heading\" aria-level=\"1\"><text color=\"rgb(0, 0, 0)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"32px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(0, 0, 0)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(0, 0, 0)\"><tspan xml:space=\"preserve\" x=\"95.140625\" y=\"44\" textLength=\"202.703125\" lengthAdjust=\"spacingAndGlyphs\">404 Not Found</tspan></text></g></g><g data-tag=\"hr\" id=\"hr1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"separator\" mask=\"url(#mask-for-hr11)\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><line stroke-linecap=\"square\" stroke=\"rgba(0, 0, 0)\" stroke-width=\"1px\" x1=\"8\" x2=\"385\" y1=\"66.4375\" y2=\"66.4375\"/><line stroke-linecap=\"square\" stroke=\"rgb(0, 0, 0)\" stroke-width=\"1px\" x1=\"8\" x2=\"385\" y1=\"68.4375\" y2=\"68.4375\"/><line stroke-linecap=\"square\" stroke=\"rgb(0, 0, 0)\" stroke-width=\"1px\" x1=\"385\" x2=\"385\" y1=\"66.4375\" y2=\"68.4375\"/><line stroke-linecap=\"square\" stroke=\"rgba(0, 0, 0)\" stroke-width=\"1px\" x1=\"8\" x2=\"8\" y1=\"66.4375\" y2=\"68.4375\"/></g><mask id=\"mask-for-hr11\"><rect width=\"377\" height=\"2\" x=\"8\" y=\"66.4375\" fill=\"#ffffff\"/></mask></g><g data-tag=\"center\" id=\"center2\" data-z-index=\"auto\" data-stacking-context=\"true\"><text color=\"rgb(0, 0, 0)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"16px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"400\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(0, 0, 0)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(0, 0, 0)\"><tspan xml:space=\"preserve\" x=\"178.265625\" y=\"93.4375\" textLength=\"36.453125\" lengthAdjust=\"spacingAndGlyphs\">nginx</tspan></text></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>\n",
      "<body><center><h1>404 Not Found</h1></center><hr><center>nginx</center></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "</style>\n",
      "Answer of the question is: \n",
      "<body><center><h1>404 Not Found</h1></center><hr><center>nginx</center></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "</style><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model, _ = FastVisionModel.from_pretrained('./output/final', \n",
    "                                        device_map=\"cuda:0\",\n",
    "                                        max_seq_length = max_seq_length,\n",
    "                                        dtype = torch.float16,\n",
    "                                        load_in_4bit = True,)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\")\n",
    "\n",
    "test_index = 0\n",
    "text = filtered_data['test'][test_index]['svg']\n",
    "model = FastVisionModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(filtered_data['test'][test_index]['svg'])\n",
    "print(filtered_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 97, in take_screenshot\n",
      "    page.goto(url)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 9018, in goto\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_page.py\", line 551, in goto\n",
      "    return await self._main_frame.goto(**locals_to_params(locals()))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_frame.py\", line 145, in goto\n",
      "    await self._channel.send(\"goto\", locals_to_params(locals()))\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 61, in send\n",
      "    return await self._connection.wrap_api_call(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TimeoutError: Page.goto: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - navigating to \"http://127.0.0.1:8893/predicted.html\", waiting until \"load\"\n",
      "\n",
      "\n",
      "Similarity: 0.9530310030860966\n",
      "Perceptual loss: 0.30120282709522517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'similarity': 0.9530310030860966, 'perceptual_loss': 0.30120282709522517}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction(model, filtered_data['test'], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9316874-a10f-45d9-9ab9-28758b27e334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
