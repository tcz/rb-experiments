{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 90B fine tuning with large data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer, AutoTokenizer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, FastVisionModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e835c55e-7bae-40a1-97af-64c78ef0e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    " \n",
    "login(\n",
    "  token=\"<HF_API_KEY_REMOVED>\", \n",
    "  add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 12000\n",
    "\n",
    "def load_model():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_compute_dtype=torch.float16,  \n",
    "        bnb_4bit_use_double_quant=True,  \n",
    "        bnb_4bit_quant_type=\"nf4\", \n",
    "    )\n",
    "\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name=\"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        quantization_config=bnb_config, \n",
    "        device_map=\"auto\" \n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\")\n",
    "    \n",
    "    model = FastVisionModel.get_peft_model(\n",
    "        model,\n",
    "\n",
    "        finetune_vision_layers     = False,\n",
    "        finetune_language_layers   = True,\n",
    "        finetune_attention_modules = True,\n",
    "        finetune_mlp_modules       = True,\n",
    "        \n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "        use_rslora=True,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state = 32,\n",
    "        loftq_config = None,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167425bb45a12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, training_data, max_steps):\n",
    "    # def collate_fn(examples):\n",
    "    #     processed_examples = [example['text'] for example in examples]\n",
    "    \n",
    "    #     batch = tokenizer(\n",
    "    #         text=processed_examples, \n",
    "    #         images=None, \n",
    "    #         return_tensors=\"pt\", \n",
    "    #         padding=True\n",
    "    #     )\n",
    "    \n",
    "    #     labels = batch[\"input_ids\"].clone()\n",
    "    #     labels[labels == tokenizer.tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    #     batch[\"labels\"] = labels\n",
    "    \n",
    "    #     return batch\n",
    "    \n",
    "    # 2 alternative = use Out of the box data collator\n",
    "    from transformers import DataCollatorForLanguageModeling\n",
    "    collate_fn = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    \n",
    "    training_arguments = UnslothTrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        embedding_learning_rate = 3e-5,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 128,\n",
    "        num_train_epochs=40,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        # max_steps=max_steps,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=150,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    if max_steps is not None:\n",
    "        training_arguments.max_steps = max_steps\n",
    "    \n",
    "    return UnslothTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=training_data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=10,\n",
    "        packing=True,\n",
    "        args=training_arguments,\n",
    "        data_collator = collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "VIEWPORT_SIZES = {\n",
    "    'DESKTOP': {'width': 1440, 'height': 900},\n",
    "    'TABLET': {'width': 834, 'height': 1210},\n",
    "    'MOBILE': {'width': 393, 'height': 852},\n",
    "}\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label, \n",
    "                                    VIEWPORT_SIZES['MOBILE']['width'], VIEWPORT_SIZES['MOBILE']['height'])\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    results = {\n",
    "        \"similarity\": float(np.mean(similarity_scores)),\n",
    "        \"perceptual_loss\": float(np.mean(perceptual_losses)),\n",
    "    }\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', results['similarity'], steps)\n",
    "    writer.add_scalar('perceptual_loss', results['perceptual_loss'], steps)\n",
    "    \n",
    "    print(\"Similarity:\", results['similarity'])\n",
    "    print(\"Perceptual loss:\", results['perceptual_loss'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    return compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9436b4-22de-4180-a7d6-9aad00934c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8b3c6163163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install zip -y\n",
    "!rm -rf data-rb-large\n",
    "!mkdir -p data-rb-large\n",
    "!wget \"https://www.dropbox.com/scl/fi/868hi141d4hrzwntxxih3/data-rb-large-with-tokenizer.zip?rlkey=md8iq2htminafzqcol3tzfbva&dl=1\" -O model.zip\n",
    "!unzip model.zip -d data-rb-large\n",
    "\n",
    "!rm -rf data-rb-validate\n",
    "!mkdir -p data-rb-validate\n",
    "!wget \"https://www.dropbox.com/scl/fi/5szml8y5l248mcabj9rqg/verify-dataset.zip?rlkey=se33rwtxgngn0ts1i0pc8f6wk&st=1d68x9zt&dl=1\" -O validate.zip\n",
    "!unzip validate.zip -d data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c94239-f780-40c6-94fd-06101b96839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.path.exists('data-rb-validate/02836284.webp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3d9ae5b9b9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "dataset = load_from_disk('data-rb-large')\n",
    "visual_validation_dataset = load_from_disk('data-rb-validate')\n",
    "\n",
    "train_test_split = dataset.train_test_split(test_size=100/len(dataset)) \n",
    "train_dataset = train_test_split[\"train\"]\n",
    "temp_dataset = train_test_split[\"test\"]\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"valid\": visual_validation_dataset,\n",
    "    \"test\": train_test_split[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c684fe8-032a-4c0d-b9ba-cb652ded3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bf3a2cdcc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.3: Fast Mllama vision patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.111 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebb19293db544ce8069053503ae2342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.vision_model.transformer` require gradients\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model()\n",
    "\n",
    "data_prompt = \"\"\"Your job is to take an SVG file of a web design and convert it into a pixel-perfect HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"svg\"]\n",
    "    outputs      = examples[\"html\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57abcb9-04a6-4ad6-91af-7fd09e7118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b25f6-18b9-4ac9-bad7-2d6ccfe2355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98a5487-c348-4ed3-ad6e-f8178cd5179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c83479923e45668059c0d5b7f0ac4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "training_data = load_from_disk('data-rb-large-filtered-50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8289ee3c-34eb-4ca3-b69b-2e7a2828a418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed57b26c23742179a36923370f7ca90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/293102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a288fc271745bca740eace85ae5404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7aaae1edc4babb5471517af3ddc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa52258f611044e792ffc8af2df67fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/293102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ae241019c445b0bc92ca167c2299b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb208629c347809df409bbee10573d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 100502\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 4\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['svg', 'html', 'text', 'input_ids', 'attention_mask', 'length'],\n",
      "        num_rows: 23\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def get_token_lengths(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=False,  # Don't truncate yet\n",
    "        padding=False,     # Don't pad yet\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = training_data.map(get_token_lengths, batched=True)\n",
    "\n",
    "def filter_function(example):\n",
    "    return example['length'] <= max_seq_length\n",
    "\n",
    "filtered_data = tokenized_data.filter(filter_function)\n",
    "\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90aeb44b-e661-4d7b-8a56-995d7e115332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47722e436fe74b749c5d90633b25f152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/23 shards):   0%|          | 0/100502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e874f02e5884918ab99ed704713eceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5457984b964730b412b58243589594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_data = filtered_data.remove_columns([\"input_ids\", \"attention_mask\", \"length\"])\n",
    "filtered_data.save_to_disk('data-rb-large-filtered-' + str(max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f049b9-5e8c-4b01-aaa1-bf0b9024d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c041b259133e4a7097b20e16aedcdb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100502\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 23\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "filtered_data = load_from_disk('data-rb-large-filtered-' + str(max_seq_length))\n",
    "\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2418c1d1-dd0b-4900-9a74-d10afa632f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some reshuffling because:\n",
    "# 1. The validation data set is arguably too simple for the 90B model and it does a pretty good job even before fine-tuning\n",
    "# 2. The test data set is too small because of the filtering\n",
    "\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "new_valid_data = concatenate_datasets([\n",
    "    filtered_data['valid'],\n",
    "    filtered_data['train'].select(range(25))\n",
    "])\n",
    "\n",
    "new_test_data = concatenate_datasets([\n",
    "    filtered_data['test'],\n",
    "    filtered_data['train'].select(range(25, 52))\n",
    "])\n",
    "\n",
    "new_train_data = filtered_data['train'].select(range(25, len(filtered_data['train'])))\n",
    "\n",
    "filtered_data = DatasetDict({\n",
    "    'train': new_train_data,\n",
    "    'valid': new_valid_data,\n",
    "    'test': new_test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a175e842-6188-427b-8ad4-5bbf85783f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100477\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 29\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae39d89303cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 0\n",
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [1:03:42<62:39:00, 3822.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9093418904598012\n",
      "Perceptual loss: 0.5067523877489669\n",
      "Steps: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a4464f8ee843eeb44d0e0d0bb1fa95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 25\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 15:40:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.620100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.723200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.708100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.655200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.607400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [21:46:57<732:18:08, 45453.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9100239964964154\n",
      "Perceptual loss: 0.4650847685748133\n",
      "Steps: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18e88b957674f9e89259fee3dd3b0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 50\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 15:38:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.630100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.636700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.629700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.550900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.647800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.536600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.545300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.563600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.524100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.509900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [44:18:15<977:14:24, 61720.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8948459789816955\n",
      "Perceptual loss: 0.35011413532855185\n",
      "Steps: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 75\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 15:37:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.591400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.545200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.336200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.275100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/60 [64:21:15<1024:19:45, 65849.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.894276197531043\n",
      "Perceptual loss: 0.3510666464230624\n",
      "Steps: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 100\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 15:36:40, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.300900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.270100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.269400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.267200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.251400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [85:16:43<1058:15:12, 69267.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9021850016770875\n",
      "Perceptual loss: 0.31624692909676455\n",
      "Steps: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 125\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 15:38:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.263900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [106:07:44<1068:33:46, 71237.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8828103464450576\n",
      "Perceptual loss: 0.3913745054140173\n",
      "Steps: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 150\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 15:36:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.259800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.227600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.237400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [126:46:26<1063:37:00, 72245.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9263129324271743\n",
      "Perceptual loss: 0.32521571562593354\n",
      "Steps: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 175\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/175 15:35:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.194600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.204400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.205500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.217300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8/60 [146:17:37<1034:28:08, 71617.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.915743907797285\n",
      "Perceptual loss: 0.318689559522117\n",
      "Steps: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 200\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 15:36:48, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.192800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.210600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.193700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.206200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9/60 [166:45:18<1023:37:47, 72256.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.951302741036064\n",
      "Perceptual loss: 0.26229281322067155\n",
      "Steps: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 225\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [225/225 15:35:48, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.198200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.199200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.203400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.195100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.243300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.227700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.198500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.209200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.214900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10/60 [187:12:18<1009:24:18, 72677.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9531804782204061\n",
      "Perceptual loss: 0.2662289510962778\n",
      "Steps: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 250\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 15:35:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.192600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.213800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [208:08:27<1000:25:41, 73500.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9235319048669342\n",
      "Perceptual loss: 0.2963933290528326\n",
      "Steps: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 275\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [275/275 15:34:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.202600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.225200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [228:31:10<979:27:07, 73458.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script failed with error: Traceback (most recent call last):\n",
      "  File \"/utils/similarity.py\", line 192, in <module>\n",
      "    take_screenshot(args.predicted_url, args.predicted_screenshot_path, args.viewport_width, args.viewport_height)\n",
      "  File \"/utils/similarity.py\", line 96, in take_screenshot\n",
      "    page = browser.new_page(viewport={'width': viewport_width, 'height': viewport_height})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/sync_api/_generated.py\", line 14169, in new_page\n",
      "    self._sync(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_sync_base.py\", line 115, in _sync\n",
      "    return task.result()\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_browser.py\", line 181, in new_page\n",
      "    return await self._connection.wrap_api_call(inner)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/playwright/_impl/_connection.py\", line 528, in wrap_api_call\n",
      "    raise rewrite_error(error, f\"{parsed_st['apiName']}: {error}\") from None\n",
      "playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed\n",
      "\n",
      "Similarity: 0.9396104334542869\n",
      "Perceptual loss: 0.256946592444652\n",
      "Steps: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 45,811 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 128\n",
      "\\        /    Total batch size = 128 | Total steps = 300\n",
      " \"-____-\"     Number of trainable parameters = 265,420,800\n",
      "🦥 Unsloth needs about 1-3 minutes to load everything - please wait!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/300 1:56:50 < 12:58:54, 0.00 it/s, Epoch 0.78/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.201200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "resume = False\n",
    "\n",
    "for steps in tqdm(range(0, 1500, 25)):\n",
    "    print(f\"Steps: {steps}\")\n",
    "\n",
    "    if steps > 0:\n",
    "        trainer = create_trainer(model, tokenizer, filtered_data['train'], steps)\n",
    "        if resume:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "            resume = True\n",
    "        \n",
    "    model = FastVisionModel.for_inference(model)\n",
    "\n",
    "    results = test_prediction(model, filtered_data['valid'], steps)\n",
    "\n",
    "    if results is not None and results['perceptual_loss'] == 0.0:\n",
    "        break\n",
    "\n",
    "    model = FastVisionModel.for_training(model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"top bottom style1\"><g data-tag=\"div\" id=\"top\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"top-left top-right\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"366.359375\" x=\"0\" y=\"0\" fill=\"rgb(128, 5, 118)\"/></g><g data-tag=\"div\" id=\"top-left\" data-z-index=\"auto\" data-stacking-context=\"true\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"200.421875\" height=\"366.359375\" x=\"0\" y=\"0\" fill=\"rgb(113, 7, 188)\"/></g><text color=\"rgb(184, 124, 151)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"29px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(184, 124, 151)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(184, 124, 151)\"><tspan xml:space=\"preserve\" x=\"0\" y=\"32\" textLength=\"103.140625\" lengthAdjust=\"spacingAndGlyphs\">BEGAN</tspan></text></g><g data-tag=\"div\" id=\"top-right\" data-z-index=\"auto\" data-stacking-context=\"true\"><text color=\"rgb(37, 86, 73)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"29px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(37, 86, 73)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(37, 86, 73)\"><tspan xml:space=\"preserve\" x=\"200.421875\" y=\"32\" textLength=\"101.5\" lengthAdjust=\"spacingAndGlyphs\">FUNNY</tspan></text></g></g><g data-tag=\"div\" id=\"bottom\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"bottom-left bottom-right\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"485.640625\" x=\"0\" y=\"366.359375\" fill=\"rgb(123, 190, 154)\"/></g><g data-tag=\"div\" id=\"bottom-left\" data-z-index=\"auto\" data-stacking-context=\"true\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"164\" height=\"485.640625\" x=\"0\" y=\"366.359375\" fill=\"rgb(173, 203, 187)\"/></g><text color=\"rgb(85, 235, 21)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"26.88px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(85, 235, 21)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(85, 235, 21)\"><tspan xml:space=\"preserve\" x=\"0\" y=\"396.359375\" textLength=\"94.09375\" lengthAdjust=\"spacingAndGlyphs\">CHOSE</tspan></text></g><g data-tag=\"div\" id=\"bottom-right\" data-z-index=\"auto\" data-stacking-context=\"true\"><text color=\"rgb(142, 139, 140)\" dominant-baseline=\"text-after-edge\" font-family=\"&quot;Times New Roman&quot;\" font-size=\"21.3333px\" font-size-adjust=\"none\" font-stretch=\"100%\" font-style=\"normal\" font-variant=\"normal\" font-weight=\"700\" direction=\"ltr\" letter-spacing=\"normal\" text-decoration=\"none solid rgb(142, 139, 140)\" text-anchor=\"start\" text-rendering=\"auto\" unicode-bidi=\"isolate\" word-spacing=\"0px\" writing-mode=\"horizontal-tb\" user-select=\"auto\" fill=\"rgb(142, 139, 140)\"><tspan xml:space=\"preserve\" x=\"164\" y=\"390.359375\" textLength=\"77.453125\" lengthAdjust=\"spacingAndGlyphs\">HARRY</tspan></text></g></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>\n",
      "<body><div id=\"top\"><div id=\"top-left\">BEGAN</div><div id=\"top-right\">FUNNY</div></div><div id=\"bottom\"><div id=\"bottom-left\">CHOSE</div><div id=\"bottom-right\">HARRY</div></div></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            margin: 0;\n",
      "            display: flex;\n",
      "            flex-direction: column;\n",
      "            min-height: 100vh;\n",
      "            font-weight: bold;\n",
      "        }\n",
      "\n",
      "        #top {\n",
      "            background-color: #800576;\n",
      "            flex-basis: 43vh;\n",
      "            flex-grow: 0;\n",
      "            flex-shrink: 0;\n",
      "            color: #255649;\n",
      "            font-size: 29px;\n",
      "        }\n",
      "\n",
      "        #bottom {\n",
      "            background-color: #7bbe9a;\n",
      "            flex: 1 1 auto;\n",
      "            color: #8e8b8c;\n",
      "            font-size: 16pt;\n",
      "        }\n",
      "\n",
      "        #top, #bottom {\n",
      "            display: flex;\n",
      "        }\n",
      "\n",
      "        #top-left {\n",
      "            flex-basis: 51vw;\n",
      "            background: #7107bc;\n",
      "            color: #b87c97;\n",
      "            font-size: 1em;\n",
      "        }\n",
      "\n",
      "        #bottom-left {\n",
      "            flex-basis: 164px;\n",
      "            background: #adcbbb;\n",
      "            color: #55eb15;\n",
      "            font-size: 126%;\n",
      "        }\n",
      "\n",
      "\n",
      "</style>\n",
      "Answer of the question is: \n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Pixel-Perfect HTML and CSS Markup</title>\n",
      "    <style>\n",
      "        /* Global Styles */\n",
      "        * {\n",
      "            box-sizing: border-box;\n",
      "            margin: 0;\n",
      "            padding: 0;\n",
      "        }\n",
      "        \n",
      "        /* Top Section Styles */\n",
      "        #top {\n",
      "            width: 393px;\n",
      "            height: 366.359375px;\n",
      "            background-color: rgb(128, 5, 118);\n",
      "        }\n",
      "        \n",
      "        #top-left {\n",
      "            width: 200.421875px;\n",
      "            height: 366.359375px;\n",
      "            background-color: rgb(113, 7, 188);\n",
      "            float: left;\n",
      "        }\n",
      "        \n",
      "        #top-left > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 29px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(184, 124, 151);\n",
      "            position: absolute;\n",
      "            top: 32px;\n",
      "            left: 0;\n",
      "        }\n",
      "        \n",
      "        #top-right {\n",
      "            float: right;\n",
      "        }\n",
      "        \n",
      "        #top-right > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 29px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(37, 86, 73);\n",
      "            position: absolute;\n",
      "            top: 32px;\n",
      "            right: 0;\n",
      "        }\n",
      "        \n",
      "        /* Bottom Section Styles */\n",
      "        #bottom {\n",
      "            width: 393px;\n",
      "            height: 485.640625px;\n",
      "            background-color: rgb(123, 190, 154);\n",
      "            clear: both;\n",
      "        }\n",
      "        \n",
      "        #bottom-left {\n",
      "            width: 164px;\n",
      "            height: 485.640625px;\n",
      "            background-color: rgb(173, 203, 187);\n",
      "            float: left;\n",
      "        }\n",
      "        \n",
      "        #bottom-left > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 26.88px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(85, 235, 21);\n",
      "            position: absolute;\n",
      "            top: 396.359375px;\n",
      "            left: 0;\n",
      "        }\n",
      "        \n",
      "        #bottom-right {\n",
      "            float: right;\n",
      "        }\n",
      "        \n",
      "        #bottom-right > span {\n",
      "            font-family: \"Times New Roman\";\n",
      "            font-size: 21.3333px;\n",
      "            font-weight: 700;\n",
      "            color: rgb(142, 139, 140);\n",
      "            position: absolute;\n",
      "            top: 390.359375px;\n",
      "            right: 0;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <div id=\"top\">\n",
      "        <div id=\"top-left\">\n",
      "            <span>BEGAN</span>\n",
      "        </div>\n",
      "        <div id=\"top-right\">\n",
      "            <span>FUNNY</span>\n",
      "        </div>\n",
      "    </div>\n",
      "    <div id=\"bottom\">\n",
      "        <div id=\"bottom-left\">\n",
      "            <span>CHOSE</span>\n",
      "        </div>\n",
      "        <div id=\"bottom-right\">\n",
      "            <span>HARRY</span>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "```\n",
      "Note that I've used the `rgb()` function to specify the colors, but you can replace them with the corresponding hex codes if needed. Also, I've assumed that the font family \"Times New Roman\" is available on the system, if not, you can replace it with a fallback font family.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "test_index = 0\n",
    "text = filtered_data['test'][test_index]['svg']\n",
    "model = FastVisionModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = max_seq_length, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(filtered_data['test'][test_index]['svg'])\n",
    "print(filtered_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(model, filtered_data['test'], steps+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4065cf71-3f41-4bb8-bf51-4faef98067ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6416387a763847db903b257f763c9472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in split:\n",
      " svg               0\n",
      "html              0\n",
      "text              0\n",
      "input_ids         0\n",
      "attention_mask    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = filtered_data['train'].select(range(1000)).map(tokenize_function, batched=True)\n",
    "\n",
    "df = tokenized_dataset.to_pandas()\n",
    "nan_counts = df.isna().sum()\n",
    "print(f\"NaN counts in split:\\n\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9316874-a10f-45d9-9ab9-28758b27e334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
