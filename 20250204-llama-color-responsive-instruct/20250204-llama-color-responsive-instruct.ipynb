{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5467970cf69d792",
   "metadata": {},
   "source": [
    "# Llama 3.2 Instruct fine tuning with color responsive\n",
    "\n",
    "2025-02-04 21:07\n",
    "\n",
    "Fine tuning Llama instruct 3.2 with the color responsive data set using unsloth. Seems to work just fine as expected. Notebook connection died, output might not be indicative, but tensorboard data is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8567da-339d-42d8-a672-fd9474f75a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu bzip2 cpp cpp-11 dirmngr\n",
      "  dpkg-dev fakeroot g++ g++-11 gcc gcc-11 gcc-11-base gnupg gnupg-l10n\n",
      "  gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan6 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl\n",
      "  libfakeroot libfile-fcntllock-perl libgcc-11-dev libgomp1 libisl23 libitm1\n",
      "  libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libquadmath0 libstdc++-11-dev libtsan0 libubsan1 lto-disabled-list make\n",
      "  patch pinentry-curses xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-11-locales dbus-user-session\n",
      "  pinentry-gnome3 tor debian-keyring g++-multilib g++-11-multilib gcc-11-doc\n",
      "  gcc-multilib manpages-dev autoconf automake libtool flex bison gdb gcc-doc\n",
      "  gcc-11-multilib parcimonie xloadimage scdaemon bzr libstdc++-11-doc make-doc\n",
      "  ed diffutils-doc pinentry-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-11 dirmngr dpkg-dev fakeroot g++ g++-11 gcc gcc-11 gcc-11-base gnupg\n",
      "  gnupg-l10n gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan6 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl\n",
      "  libfakeroot libfile-fcntllock-perl libgcc-11-dev libgomp1 libisl23 libitm1\n",
      "  libksba8 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libquadmath0 libstdc++-11-dev libtsan0 libubsan1 lto-disabled-list make\n",
      "  patch pinentry-curses xz-utils\n",
      "0 upgraded, 53 newly installed, 0 to remove and 36 not upgraded.\n",
      "Need to get 62.3 MB of archives.\n",
      "After this operation, 198 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 xz-utils amd64 5.2.5-2ubuntu1 [84.8 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.6 [222 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.6 [662 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf-nobfd0 amd64 2.38-4ubuntu2.6 [108 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.6 [103 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.6 [2326 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.6 [3200 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-11-base amd64 11.4.0-1ubuntu1~22.04 [20.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libisl23 amd64 0.24-2build1 [727 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmpfr6 amd64 4.1.0-3build3 [1425 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmpc3 amd64 1.2.1-2build1 [46.9 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-11 amd64 11.4.0-1ubuntu1~22.04 [10.0 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 cpp amd64 4:11.2.0-1ubuntu1 [27.7 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcc1-0 amd64 12.3.0-1ubuntu1~22.04 [48.3 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgomp1 amd64 12.3.0-1ubuntu1~22.04 [126 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libitm1 amd64 12.3.0-1ubuntu1~22.04 [30.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libatomic1 amd64 12.3.0-1ubuntu1~22.04 [10.4 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan6 amd64 11.4.0-1ubuntu1~22.04 [2282 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 liblsan0 amd64 12.3.0-1ubuntu1~22.04 [1069 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan0 amd64 11.4.0-1ubuntu1~22.04 [2260 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libubsan1 amd64 12.3.0-1ubuntu1~22.04 [976 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libquadmath0 amd64 12.3.0-1ubuntu1~22.04 [154 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-11-dev amd64 11.4.0-1ubuntu1~22.04 [2517 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-11 amd64 11.4.0-1ubuntu1~22.04 [20.1 MB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 gcc amd64 4:11.2.0-1ubuntu1 [5112 B]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libstdc++-11-dev amd64 11.4.0-1ubuntu1~22.04 [2101 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 g++-11 amd64 11.4.0-1ubuntu1~22.04 [11.4 MB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 g++ amd64 4:11.2.0-1ubuntu1 [1412 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 make amd64 4.3-4.1build1 [180 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdpkg-perl all 1.21.1ubuntu2.3 [237 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 bzip2 amd64 1.0.8-5build1 [34.8 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 patch amd64 2.7.6-7build2 [109 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 lto-disabled-list all 24 [12.5 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dpkg-dev all 1.21.1ubuntu2.3 [922 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 build-essential amd64 12.9ubuntu3 [4744 B]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libksba8 amd64 1.6.0-2ubuntu0.2 [119 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnpth0 amd64 1.6-3build2 [8664 B]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dirmngr amd64 2.2.27-3ubuntu2.1 [293 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg-l10n all 2.2.27-3ubuntu2.1 [54.4 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg-utils amd64 2.2.27-3ubuntu2.1 [308 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 pinentry-curses amd64 1.1.1-1build2 [34.4 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-agent amd64 2.2.27-3ubuntu2.1 [209 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-wks-client amd64 2.2.27-3ubuntu2.1 [62.7 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpg-wks-server amd64 2.2.27-3ubuntu2.1 [57.5 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gpgsm amd64 2.2.27-3ubuntu2.1 [197 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gnupg all 2.2.27-3ubuntu2.1 [315 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-diff-perl all 1.201-1 [41.8 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-diff-xs-perl amd64 0.04-6build3 [11.9 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 libalgorithm-merge-perl all 0.08-3 [12.0 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfile-fcntllock-perl amd64 0.22-3build7 [33.9 kB]\n",
      "Fetched 62.3 MB in 2s (28.3 MB/s)                   \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "(Reading database ... 16754 files and directories currently installed.)\n",
      "Preparing to unpack .../00-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../01-xz-utils_5.2.5-2ubuntu1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.5-2ubuntu1) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../02-binutils-common_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../03-libbinutils_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../04-libctf-nobfd0_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libctf-nobfd0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../05-libctf0_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking libctf0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../06-binutils-x86-64-linux-gnu_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../07-binutils_2.38-4ubuntu2.6_amd64.deb ...\n",
      "Unpacking binutils (2.38-4ubuntu2.6) ...\n",
      "Selecting previously unselected package gcc-11-base:amd64.\n",
      "Preparing to unpack .../08-gcc-11-base_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking gcc-11-base:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libisl23:amd64.\n",
      "Preparing to unpack .../09-libisl23_0.24-2build1_amd64.deb ...\n",
      "Unpacking libisl23:amd64 (0.24-2build1) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../10-libmpfr6_4.1.0-3build3_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.1.0-3build3) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../11-libmpc3_1.2.1-2build1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.2.1-2build1) ...\n",
      "Selecting previously unselected package cpp-11.\n",
      "Preparing to unpack .../12-cpp-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking cpp-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../13-cpp_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking cpp (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../14-libcc1-0_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../15-libgomp1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libgomp1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../16-libitm1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../17-libatomic1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libasan6:amd64.\n",
      "Preparing to unpack .../18-libasan6_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libasan6:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../19-liblsan0_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../20-libtsan0_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libtsan0:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../21-libubsan1_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../22-libquadmath0_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libgcc-11-dev:amd64.\n",
      "Preparing to unpack .../23-libgcc-11-dev_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libgcc-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gcc-11.\n",
      "Preparing to unpack .../24-gcc-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking gcc-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../25-gcc_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking gcc (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package libstdc++-11-dev:amd64.\n",
      "Preparing to unpack .../26-libstdc++-11-dev_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking libstdc++-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package g++-11.\n",
      "Preparing to unpack .../27-g++-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking g++-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../28-g++_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking g++ (4:11.2.0-1ubuntu1) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../29-make_4.3-4.1build1_amd64.deb ...\n",
      "Unpacking make (4.3-4.1build1) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../30-libdpkg-perl_1.21.1ubuntu2.3_all.deb ...\n",
      "Unpacking libdpkg-perl (1.21.1ubuntu2.3) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../31-bzip2_1.0.8-5build1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.8-5build1) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../32-patch_2.7.6-7build2_amd64.deb ...\n",
      "Unpacking patch (2.7.6-7build2) ...\n",
      "Selecting previously unselected package lto-disabled-list.\n",
      "Preparing to unpack .../33-lto-disabled-list_24_all.deb ...\n",
      "Unpacking lto-disabled-list (24) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../34-dpkg-dev_1.21.1ubuntu2.3_all.deb ...\n",
      "Unpacking dpkg-dev (1.21.1ubuntu2.3) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../35-build-essential_12.9ubuntu3_amd64.deb ...\n",
      "Unpacking build-essential (12.9ubuntu3) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../36-libksba8_1.6.0-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.6.0-2ubuntu0.2) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../37-libnpth0_1.6-3build2_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-3build2) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../38-dirmngr_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../39-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../40-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
      "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../41-gnupg-l10n_2.2.27-3ubuntu2.1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../42-gnupg-utils_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../43-pinentry-curses_1.1.1-1build2_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.1.1-1build2) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../44-gpg-agent_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../45-gpg-wks-client_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../46-gpg-wks-server_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../47-gpgsm_2.2.27-3ubuntu2.1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../48-gnupg_2.2.27-3ubuntu2.1_all.deb ...\n",
      "Unpacking gnupg (2.2.27-3ubuntu2.1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../49-libalgorithm-diff-perl_1.201-1_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.201-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl.\n",
      "Preparing to unpack .../50-libalgorithm-diff-xs-perl_0.04-6build3_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl (0.04-6build3) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../51-libalgorithm-merge-perl_0.08-3_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-3) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../52-libfile-fcntllock-perl_0.22-3build7_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-3build7) ...\n",
      "Setting up libksba8:amd64 (1.6.0-2ubuntu0.2) ...\n",
      "Setting up pinentry-curses (1.1.1-1build2) ...\n",
      "Setting up gcc-11-base:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up lto-disabled-list (24) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-3build7) ...\n",
      "Setting up libalgorithm-diff-perl (1.201-1) ...\n",
      "Setting up gpgsm (2.2.27-3ubuntu2.1) ...\n",
      "Setting up binutils-common:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libctf-nobfd0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libnpth0:amd64 (1.6-3build2) ...\n",
      "Setting up libgomp1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up bzip2 (1.0.8-5build1) ...\n",
      "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
      "Setting up libasan6:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up fakeroot (1.28-1ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up dirmngr (2.2.27-3ubuntu2.1) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/dirmngr.socket → /usr/lib/systemd/user/dirmngr.socket.\n",
      "Setting up make (4.3-4.1build1) ...\n",
      "Setting up libmpfr6:amd64 (4.1.0-3build3) ...\n",
      "Setting up gnupg-l10n (2.2.27-3ubuntu2.1) ...\n",
      "Setting up xz-utils (5.2.5-2ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libmpc3:amd64 (1.2.1-2build1) ...\n",
      "Setting up libatomic1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up patch (2.7.6-7build2) ...\n",
      "Setting up libdpkg-perl (1.21.1ubuntu2.3) ...\n",
      "Setting up libubsan1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libbinutils:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up libisl23:amd64 (0.24-2build1) ...\n",
      "Setting up libalgorithm-diff-xs-perl (0.04-6build3) ...\n",
      "Setting up libcc1-0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
      "Setting up liblsan0:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libitm1:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-3) ...\n",
      "Setting up gnupg-utils (2.2.27-3ubuntu2.1) ...\n",
      "Setting up libtsan0:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up libctf0:amd64 (2.38-4ubuntu2.6) ...\n",
      "Setting up cpp-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gpg-agent (2.2.27-3ubuntu2.1) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-browser.socket → /usr/lib/systemd/user/gpg-agent-browser.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-extra.socket → /usr/lib/systemd/user/gpg-agent-extra.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-ssh.socket → /usr/lib/systemd/user/gpg-agent-ssh.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent.socket → /usr/lib/systemd/user/gpg-agent.socket.\n",
      "Setting up gpg-wks-client (2.2.27-3ubuntu2.1) ...\n",
      "Setting up gpg-wks-server (2.2.27-3ubuntu2.1) ...\n",
      "Setting up libgcc-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up cpp (4:11.2.0-1ubuntu1) ...\n",
      "Setting up gnupg (2.2.27-3ubuntu2.1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.6) ...\n",
      "Setting up binutils (2.38-4ubuntu2.6) ...\n",
      "Setting up dpkg-dev (1.21.1ubuntu2.3) ...\n",
      "Setting up libstdc++-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gcc-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up g++-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Setting up gcc (4:11.2.0-1ubuntu1) ...\n",
      "Setting up g++ (4:11.2.0-1ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/c++.1.gz because associated file /usr/share/man/man1/g++.1.gz (of link group c++) doesn't exist\n",
      "Setting up build-essential (12.9ubuntu3) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.1.8-py3-none-any.whl.metadata (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.9/53.9 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting unsloth_zoo>=2025.1.4 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.1.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (2.4.0)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (3.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from unsloth) (24.1)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.4/44.4 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting datasets>=2.16.0 (from unsloth)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from unsloth) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from unsloth) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unsloth) (1.26.4)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting huggingface_hub (from unsloth)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.1->unsloth) (6.0.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.34.1->unsloth)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth)\n",
      "  Downloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=2.16.0->unsloth)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.9/89.9 kB\u001B[0m \u001B[31m39.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
      "Collecting aiohttp (from datasets>=2.16.0->unsloth)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->unsloth) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.47.0,>=4.46.1->unsloth)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.5/40.5 kB\u001B[0m \u001B[31m15.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,>=4.46.1->unsloth)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting rich (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.1.4->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo>=2025.1.4->unsloth) (10.4.0)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.16.0->unsloth)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.2/69.2 kB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.7.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=2.16.0->unsloth)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
      "Downloading unsloth-2025.1.8-py3-none-any.whl (175 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m175.5/175.5 kB\u001B[0m \u001B[31m54.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m336.6/336.6 kB\u001B[0m \u001B[31m106.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m124.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m464.1/464.1 kB\u001B[0m \u001B[31m126.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m374.8/374.8 kB\u001B[0m \u001B[31m116.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m162.1/162.1 kB\u001B[0m \u001B[31m69.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m164.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/9.7 MB\u001B[0m \u001B[31m186.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading trl-0.14.0-py3-none-any.whl (313 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m313.9/313.9 kB\u001B[0m \u001B[31m93.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading unsloth_zoo-2025.1.5-py3-none-any.whl (80 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m80.2/80.2 kB\u001B[0m \u001B[31m39.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.3/15.3 MB\u001B[0m \u001B[31m15.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m906.5/906.5 MB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.5/209.5 MB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m172.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m137.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m154.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m14.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m39.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m101.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m58.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m37.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m188.7/188.7 MB\u001B[0m \u001B[31m41.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m157.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m38.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m192.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.7/69.7 MB\u001B[0m \u001B[31m89.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m179.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.7/115.7 kB\u001B[0m \u001B[31m44.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m53.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m162.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m54.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.1/42.1 MB\u001B[0m \u001B[31m120.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m792.7/792.7 kB\u001B[0m \u001B[31m147.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m242.4/242.4 kB\u001B[0m \u001B[31m91.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m462.0/462.0 kB\u001B[0m \u001B[31m123.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m185.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m191.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.8/194.8 kB\u001B[0m \u001B[31m74.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m274.9/274.9 kB\u001B[0m \u001B[31m93.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m87.5/87.5 kB\u001B[0m \u001B[31m41.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.0/129.0 kB\u001B[0m \u001B[31m62.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m231.1/231.1 kB\u001B[0m \u001B[31m83.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m346.8/346.8 kB\u001B[0m \u001B[31m106.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m344.1/344.1 kB\u001B[0m \u001B[31m111.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: sentencepiece, xxhash, tzdata, typeguard, triton, sympy, shtab, safetensors, regex, pyarrow, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, mdurl, hf_transfer, frozenlist, docstring-parser, dill, aiohappyeyeballs, yarl, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, huggingface_hub, aiosignal, tokenizers, rich, nvidia-cusolver-cu12, aiohttp, tyro, transformers, torch, xformers, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "!pip install sacrebleu\n",
    "!pip install pytest-playwright\n",
    "!playwright install\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install torchvision\n",
    "!pip install lpips\n",
    "\n",
    "!playwright install-deps  \n",
    "\n",
    "!pip install -U numpy\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae539acb48bf192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "# Saving model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b19b466d146db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 5020\n",
    "def load_model():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=\"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    \n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "        use_rslora=True,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state = 32,\n",
    "        loftq_config = None,\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167425bb45a12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, training_data, max_steps):\n",
    "    return SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=training_data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=2,\n",
    "        packing=True,\n",
    "        args=TrainingArguments(\n",
    "            learning_rate=3e-4,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            per_device_train_batch_size=16,\n",
    "            gradient_accumulation_steps=8,\n",
    "            num_train_epochs=1,\n",
    "            fp16=not is_bfloat16_supported(),\n",
    "            bf16=is_bfloat16_supported(),\n",
    "            logging_steps=1,\n",
    "            max_steps=max_steps,\n",
    "            optim=\"adamw_8bit\",\n",
    "            weight_decay=0.01,\n",
    "            warmup_steps=10,\n",
    "            output_dir=\"output\",\n",
    "            seed=0,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954eacb08fd7d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.similarity import calculate_metrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "log_dir = 'output/runs'\n",
    "\n",
    "def add_image_to_tensorboard(name, step, img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    image_tensor = torch.from_numpy(image_array)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "    image_tensor = image_tensor.float() / 255.0\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_image(name, image_tensor, step)\n",
    "    \n",
    "def add_text_to_tensorboard(name, step, text):\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text(name, text, step)\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip().replace('<unk>', '') for pred in preds]\n",
    "    labels = [[label.strip().replace('<unk>', '')] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(decoded_predictions, decoded_labels, steps):\n",
    "    similarity_scores = []\n",
    "    perceptual_losses = []\n",
    "    index = 1\n",
    "    \n",
    "    for prediction, label in zip(decoded_predictions, decoded_labels):\n",
    "        prediction = prediction.replace(tokenizer.eos_token, '')\n",
    "        \n",
    "        add_text_to_tensorboard(f'valid_{index}_label_text', steps, label)\n",
    "        add_text_to_tensorboard(f'valid_{index}_prediction_text', steps, prediction)\n",
    "        \n",
    "        metrics = calculate_metrics(prediction, label)\n",
    "        \n",
    "        if metrics is not None:\n",
    "            similarity_scores.append(metrics['similarity'])\n",
    "            perceptual_losses.append(metrics['perceptual_loss'])\n",
    "            \n",
    "            add_image_to_tensorboard(f'valid_{index}_expectation', steps, metrics['expected_screenshot_path'])\n",
    "            add_image_to_tensorboard(f'valid_{index}_prediction', steps, metrics['predicted_screenshot_path'])\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_scalar('similarity', float(np.mean(similarity_scores)), steps)\n",
    "    writer.add_scalar('perceptual_loss', float(np.mean(perceptual_losses)), steps)\n",
    "    \n",
    "    print(\"Similarity:\", float(np.mean(similarity_scores)))\n",
    "    print(\"Perceptual loss:\", float(np.mean(perceptual_losses)))\n",
    "\n",
    "def test_prediction(model, data, steps):\n",
    "    answers = []\n",
    "    labels = []\n",
    "    print(\"Generating predictions...\")\n",
    "    for row in data:\n",
    "        inputs = tokenizer(\n",
    "        [\n",
    "            data_prompt.format(\n",
    "                #instructions\n",
    "                row['svg'],\n",
    "                #answer\n",
    "                \"\",\n",
    "            )\n",
    "        ], return_tensors = \"pt\").to(\"cuda\")\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "        answer = tokenizer.batch_decode(outputs)\n",
    "        answers.append(answer[0].split(\"### Response:\")[-1])\n",
    "        labels.append(row['html'])\n",
    "\n",
    "    print(\"Computing metrics...\")\n",
    "    compute_metrics(answers, labels, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8b3c6163163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output\n",
    "\n",
    "!apt install zip -y\n",
    "!rm -rf data-rb-color-responsive\n",
    "!mkdir -p data-rb-color-responsive\n",
    "!wget \"https://www.dropbox.com/scl/fi/ei7ere3ecrr58ovgbps3i/color-responsive.zip.zip?rlkey=7dnmece3kixgk7s7khds27xu5&st=hufvmpnc&dl=1\" -O model.zip\n",
    "!unzip model.zip -d data-rb-color-responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba8d4f-8478-4330-a639-b359f4209d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data-rb-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3d9ae5b9b9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('data-rb-color-responsive')\n",
    "dataset = dataset.train_test_split(test_size=4/len(dataset))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ace974-5fab-4939-a944-8311078744eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mobile: \\n\\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"style1\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"852\" x=\"0\" y=\"0\" fill=\"rgb(117, 18, 23)\"/></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>\\n\\nDesktop:\\n\\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1440\" height=\"900\" viewBox=\"0 0 1440 900\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"style1\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"1440\" height=\"900\" x=\"0\" y=\"0\" fill=\"rgb(235, 114, 116)\"/></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bf3a2cdcc7b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.1.8: Fast Llama patching. Transformers: 4.48.2.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.111 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2050a826807443ae8d8730f3163f3bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd11799132542be9ea2987867ea269a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f5cd94fbad48138ed975cc901660ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a78b9f510e432a89cf172e3616004d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce935ffbaed4a82900cf5e7ec87e73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.1.8 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd727c1a32e54043942109ff545ab040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd4deada41b458d8b4eea6a483c6bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model()\n",
    "\n",
    "data_prompt = \"\"\"Your job is to take two SVG files of a web design (mobile and desktop) and convert it into a pixel-perfect, responsive HTML and CSS markup and stylesheet.\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"svg\"]\n",
    "    outputs      = examples[\"html\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "training_data = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335b25f6-18b9-4ac9-bad7-2d6ccfe2355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 100508\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['svg', 'html', 'text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a8ef30-7fc5-4d6b-8336-248631d585d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            background-color: #3bc60f;\n",
      "            margin: 0;\n",
      "        }\n",
      "\n",
      "        @media (min-width: 768px) {\n",
      "            body {\n",
      "                background-color: #43786c;\n",
      "            }\n",
      "        }\n",
      "\n",
      "    \n",
      "\n",
      "</style>\n"
     ]
    }
   ],
   "source": [
    "print(training_data['test'][0]['svg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae39d89303cb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 0\n",
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [03:59<1:07:47, 239.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7470341289415956\n",
      "Perceptual loss: 0.6158445477485657\n",
      "Steps: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2a02829d8f44bc8d91a2943b687758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 100\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 40:37, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.268700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.261300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.237900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.237800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.236900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [47:19<7:14:11, 1628.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8033537467941642\n",
      "Perceptual loss: 0.49488016963005066\n",
      "Steps: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b909f261938419cbd497bb87c8819a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 200\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 40:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.229600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.229800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.227900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.225300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [1:30:22<8:36:00, 2064.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.863379393145442\n",
      "Perceptual loss: 0.49375153332948685\n",
      "Steps: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 300\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 40:38, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.226200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.225300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.448700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.224700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [2:12:22<8:43:36, 2244.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.8422791164368392\n",
      "Perceptual loss: 0.4914837032556534\n",
      "Steps: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 400\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 40:33, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.223700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.222300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.222300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.211700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>0.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.211400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.209600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5/18 [2:54:22<8:27:44, 2343.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9172596634831279\n",
      "Perceptual loss: 0.3807985782623291\n",
      "Steps: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 40:29, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>0.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.207400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.204200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>0.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>0.200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>0.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.196200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.194700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>0.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>0.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>0.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>0.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>0.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>0.187300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.184400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>0.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>0.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>0.181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.179700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>0.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>0.178700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>0.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.177300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>0.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>0.175800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>0.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>0.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>0.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>0.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>0.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.170600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.170200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>0.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>0.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>0.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>0.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>0.167200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>0.167200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.165900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>0.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>0.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>0.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>0.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>0.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>0.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.164100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>0.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 6/18 [3:36:22<8:00:42, 2403.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9843414062888769\n",
      "Perceptual loss: 0.1987664263579063\n",
      "Steps: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 600\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 40:12, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>0.172200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507</td>\n",
       "      <td>0.178200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>0.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td>0.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511</td>\n",
       "      <td>0.170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>0.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>0.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>0.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>0.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.163200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>0.160600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>0.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>0.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>0.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>0.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>0.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>0.159400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>0.158200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>0.158500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>0.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>0.158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>0.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>0.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>0.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>0.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>0.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>0.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>0.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>0.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>0.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>0.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>0.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>0.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>569</td>\n",
       "      <td>0.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573</td>\n",
       "      <td>0.151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.154400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577</td>\n",
       "      <td>0.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>0.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>0.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>591</td>\n",
       "      <td>0.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>0.152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593</td>\n",
       "      <td>0.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>0.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>0.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>0.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>0.152500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [4:17:58<7:26:12, 2433.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9980227237714012\n",
      "Perceptual loss: 0.044182714947964996\n",
      "Steps: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 700\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 40:04, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>601</td>\n",
       "      <td>0.151500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603</td>\n",
       "      <td>0.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>0.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>0.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>0.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614</td>\n",
       "      <td>0.150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>0.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>0.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>0.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>628</td>\n",
       "      <td>0.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>631</td>\n",
       "      <td>0.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>634</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>639</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>644</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>0.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>653</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>656</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>658</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>661</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>667</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>668</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>669</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>679</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>681</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>0.150200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>0.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>689</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>692</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.149600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [4:59:22<6:48:17, 2449.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.998181082486672\n",
      "Perceptual loss: 0.04140920651843771\n",
      "Steps: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 4\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 800\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 40:12, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>703</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>0.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>0.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>717</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>718</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>719</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>721</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>723</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>724</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>727</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>729</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>733</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>734</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>739</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>746</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>0.150700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>0.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>758</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>759</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>762</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>769</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>771</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>0.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>773</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>774</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>776</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>779</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>786</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>787</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>789</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>791</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>793</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>794</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 9/18 [5:40:58<6:09:38, 2464.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9952935974922461\n",
      "Perceptual loss: 0.0498990555643104\n",
      "Steps: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 4\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 900\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 40:15, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>801</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>804</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>809</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>811</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>812</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>813</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>817</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>821</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>837</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>838</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>839</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>841</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>844</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>854</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>857</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>859</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>863</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>866</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>871</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>872</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>873</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>879</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>881</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>883</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>884</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>897</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>898</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>899</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [6:22:30<5:29:42, 2472.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9981806728000542\n",
      "Perceptual loss: 0.0410763276158832\n",
      "Steps: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 4\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,000\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 40:13, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>901</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>902</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>904</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>906</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>907</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>908</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>909</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>911</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>912</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>913</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>914</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>917</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>918</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>919</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>921</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>922</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>923</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>926</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>929</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>937</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>938</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>939</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>943</td>\n",
       "      <td>0.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>0.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>946</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>947</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>948</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>952</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>954</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>961</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>964</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>966</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>967</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>968</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>969</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>977</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>979</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>981</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>982</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>986</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>988</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>989</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>993</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>994</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [7:04:09<4:49:26, 2480.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9981825841838146\n",
      "Perceptual loss: 0.041022165678441525\n",
      "Steps: 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,100\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/1100 40:15, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005</td>\n",
       "      <td>0.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1006</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1007</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1009</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1011</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1012</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1013</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1014</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1016</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1017</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1018</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1022</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1023</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1026</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1027</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1028</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1029</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1033</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1036</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1037</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1038</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1039</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1041</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1042</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1043</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1044</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1046</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1047</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1048</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1049</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1052</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1054</td>\n",
       "      <td>0.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1056</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1057</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1058</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1059</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1061</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1062</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1063</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1064</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1066</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1067</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1068</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1069</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1071</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1072</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1073</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1074</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1076</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1077</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1078</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1081</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1082</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1083</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1084</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1086</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1087</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1089</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1093</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1094</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1096</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1099</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [7:45:43<4:08:28, 2484.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9952953993779374\n",
      "Perceptual loss: 0.04984685592353344\n",
      "Steps: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 5\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,200\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 40:13, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1101</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1102</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1103</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1106</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1108</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1109</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1112</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1114</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1115</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1116</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1117</td>\n",
       "      <td>0.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1118</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1121</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1122</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1123</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1124</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1126</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1127</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1128</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1129</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1131</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1132</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1133</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1135</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1136</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1137</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1138</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1139</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1141</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1142</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1143</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1145</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1146</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1147</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1148</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1149</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1151</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1152</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1153</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1154</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1156</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1158</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1159</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1161</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1162</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1163</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1166</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1167</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1168</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1169</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1171</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1172</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1173</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1174</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1177</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1178</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1179</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1181</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1183</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1184</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1185</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1186</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1187</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1189</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1191</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1192</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1196</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1197</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1198</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1199</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 13/18 [8:27:21<3:27:24, 2488.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9973616186965956\n",
      "Perceptual loss: 0.04740855749696493\n",
      "Steps: 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,300\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 40:14, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1201</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1202</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1203</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1204</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1205</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1206</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1207</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1208</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1209</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1211</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1212</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1213</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>0.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1223</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1224</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1226</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1227</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1228</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1229</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1231</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1232</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1233</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1234</td>\n",
       "      <td>0.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1236</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1237</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1238</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1239</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1241</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1242</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1243</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1244</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1246</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1247</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1248</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1249</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1251</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1252</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1253</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1254</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1256</td>\n",
       "      <td>0.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1257</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1258</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1259</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1261</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1262</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1263</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1264</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1266</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1267</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1268</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1269</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1272</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1273</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1274</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1276</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1277</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1278</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1279</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1281</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1282</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1283</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1287</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1288</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1289</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1291</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1292</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1293</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1294</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1297</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1298</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1299</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [9:08:56<2:46:02, 2490.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9981835192302242\n",
      "Perceptual loss: 0.041303678415715694\n",
      "Steps: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,400\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1400' max='1400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1400/1400 40:11, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1301</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1302</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1303</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1309</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1311</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1312</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1313</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1314</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1315</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1316</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1317</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1318</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1319</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1321</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1322</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1323</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1324</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1326</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1327</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1328</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1329</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1331</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1332</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1333</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1334</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1336</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1337</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1339</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1341</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1342</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1343</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1345</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1346</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1347</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1348</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1349</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1351</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1352</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1353</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1354</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1355</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1356</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1357</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1358</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1359</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1361</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1362</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1363</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1364</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1367</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1368</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1369</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1371</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1372</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1373</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1374</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1376</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1377</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1378</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1379</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1381</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1382</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1383</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1384</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1385</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1386</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1387</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1388</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1389</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1391</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1392</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1393</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1394</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1397</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1398</td>\n",
       "      <td>0.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1399</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [9:50:33<2:04:37, 2492.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9973616186965956\n",
      "Perceptual loss: 0.04740855749696493\n",
      "Steps: 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 6\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,500\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 40:18, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1401</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1402</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1403</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1404</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1405</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1406</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1407</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1408</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1409</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1411</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1412</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1413</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1414</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1416</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1417</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1418</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1422</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1423</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1426</td>\n",
       "      <td>0.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1427</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1429</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1431</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1432</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1433</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1434</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1435</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1436</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1437</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1438</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1439</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1441</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1442</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1443</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1445</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1446</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1447</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1448</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1449</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1451</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1452</td>\n",
       "      <td>0.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1453</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1454</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1459</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1461</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1462</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1466</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1467</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1468</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1469</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1471</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1472</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1473</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1474</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1476</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1477</td>\n",
       "      <td>0.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1478</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1479</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1481</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1482</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1483</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1484</td>\n",
       "      <td>0.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1486</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1487</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1488</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1489</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1491</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1492</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1493</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1494</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1497</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [10:32:18<1:23:12, 2496.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9944734988443088\n",
      "Perceptual loss: 0.05595173500478268\n",
      "Steps: 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,600\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/1600 38:53, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1501</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1502</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1503</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1504</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1506</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1507</td>\n",
       "      <td>0.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1508</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1509</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1511</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1512</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1513</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1514</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1515</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1516</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1517</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1518</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1519</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1522</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1523</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1524</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1526</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1527</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1528</td>\n",
       "      <td>0.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1529</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1531</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1532</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1534</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1535</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1537</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1538</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1539</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1541</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1542</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1543</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1544</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1546</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1547</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1548</td>\n",
       "      <td>0.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1549</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1551</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1552</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1553</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1554</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1556</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1557</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1558</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1559</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1561</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1562</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1563</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1564</td>\n",
       "      <td>0.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1566</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1567</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1568</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1569</td>\n",
       "      <td>0.145400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1571</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1572</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1573</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1574</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1576</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1577</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1578</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1579</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1581</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1582</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1583</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1584</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1585</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1586</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1587</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1588</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1589</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1591</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1592</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1593</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1594</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>0.146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 17/18 [11:12:35<41:12, 2472.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9981835192302242\n",
      "Perceptual loss: 0.041303678415715694\n",
      "Steps: 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 32,154 | Num Epochs = 7\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 128 | Total steps = 1,700\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1700' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1700/1700 38:37, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1601</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1602</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1603</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1604</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1606</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1607</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1608</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1609</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1611</td>\n",
       "      <td>0.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1612</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1613</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1614</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1615</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1616</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1617</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1618</td>\n",
       "      <td>0.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1619</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1621</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1622</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1623</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1624</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1626</td>\n",
       "      <td>0.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1627</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1628</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1629</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1631</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1632</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1633</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1634</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1635</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1636</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1638</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1639</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1641</td>\n",
       "      <td>0.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1642</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1643</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1644</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1646</td>\n",
       "      <td>0.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1648</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1651</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1652</td>\n",
       "      <td>0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1653</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1654</td>\n",
       "      <td>0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1655</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1656</td>\n",
       "      <td>0.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1657</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1658</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1659</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1661</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1662</td>\n",
       "      <td>0.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1663</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1664</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>0.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1666</td>\n",
       "      <td>0.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1667</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1668</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1669</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1673</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1674</td>\n",
       "      <td>0.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1676</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1677</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1678</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1679</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1681</td>\n",
       "      <td>0.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1682</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1683</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1684</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1685</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1686</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1687</td>\n",
       "      <td>0.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1688</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1689</td>\n",
       "      <td>0.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1691</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1692</td>\n",
       "      <td>0.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1693</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1694</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1695</td>\n",
       "      <td>0.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1696</td>\n",
       "      <td>0.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1697</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1698</td>\n",
       "      <td>0.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1699</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [11:52:27<00:00, 2374.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9944734988443088\n",
      "Perceptual loss: 0.05595173500478268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "resume = False\n",
    "for steps in tqdm(range(0, 1701, 100)):\n",
    "    print(f\"Steps: {steps}\")\n",
    "\n",
    "    if steps > 0:\n",
    "        trainer = create_trainer(model, tokenizer, training_data['train'], steps)\n",
    "        if resume:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "            resume = True\n",
    "        \n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "    test_prediction(model, training_data['test'], steps)\n",
    "\n",
    "    model = FastLanguageModel.for_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14378b83-4627-4812-aebd-07bdcc899bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            background-color: #096c3a;\n",
      "            margin: 0;\n",
      "        }\n",
      "\n",
      "        @media (min-width: 768px) {\n",
      "            body {\n",
      "                background-color: #971471;\n",
      "            }\n",
      "        }\n",
      "\n",
      "    \n",
      "\n",
      "</style>\n",
      "Answer of the question is: \n",
      "<body></body>\n",
      "\n",
      "<style>\n",
      "\n",
      "\n",
      "        body {\n",
      "            background-color: #096c3a;\n",
      "            margin: 0;\n",
      "        }\n",
      "\n",
      "        @media (min-width: 768px) {\n",
      "            body {\n",
      "                background-color: #971471;\n",
      "            }\n",
      "        }\n",
      "\n",
      "    \n",
      "\n",
      "</style><|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "test_index = 3\n",
    "text = training_data['test'][test_index]['svg']\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    data_prompt.format(\n",
    "        #instructions\n",
    "        text,\n",
    "        #answer\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 5020, use_cache = True)\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer = answer[0].split(\"### Response:\")[-1]\n",
    "\n",
    "print(training_data['test'][test_index]['html'])\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f2df0f9-6c3c-4024-99b0-f6d7832875fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Computing metrics...\n",
      "Similarity: 1.0\n",
      "Perceptual loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_prediction(model, training_data['test'], steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fdf7c2f-841d-43e1-94e4-bcc027f137ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mobile: \\n\\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"393\" height=\"852\" viewBox=\"0 0 393 852\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"style1\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"393\" height=\"852\" x=\"0\" y=\"0\" fill=\"rgb(59, 198, 15)\"/></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>\\n\\nDesktop:\\n\\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1440\" height=\"900\" viewBox=\"0 0 1440 900\"><g id=\"html1\"><g data-tag=\"head\" id=\"head1\" data-z-index=\"auto\" data-stacking-context=\"true\" aria-owns=\"script1\"><g data-tag=\"script\" id=\"script1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g><g data-tag=\"body\" id=\"body1\" data-z-index=\"auto\" data-stacking-context=\"true\" role=\"document\" aria-owns=\"style1\"><g data-stacking-layer=\"rootBackgroundAndBorders\"><rect width=\"1440\" height=\"900\" x=\"0\" y=\"0\" fill=\"rgb(67, 120, 108)\"/></g><g data-tag=\"style\" id=\"style1\" data-z-index=\"auto\" data-stacking-context=\"true\"/></g></g></svg>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f529a-e8d0-4c77-84ba-03186948c069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
